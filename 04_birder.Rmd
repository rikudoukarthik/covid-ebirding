---
output: html_document
editor_options: 
  chunk_output_type: console
---

# Birder behaviour (focus level: checklists)

Changes in eBirder behaviour will be analysed using the focal data point, checklists. A number of metrics based on checklists will be calculated and analysed (**at the monthly scale**), such as:

1.  Number of submitted checklists
    1.  Total lists\
    2.  Shared lists (use no. of obs.)\
2.  Number of submitted checklists per observer
    1.  Total lists\
    2.  Shared lists (use no. of obs.)\
3.  Hotspot birding\
4.  Birding protocol\
5.  Birding distance
6.  Site fidelity per observer\
7.  Habitats surveyed\
8.  Spatial spread of birding activity. These spatial patterns will be explored at two scales too: nationwide and regional.
    1.  Spatial spread by absences\
    2.  Spatial spread by densities\
9.  List duration
10. List length\
11. Birding time per observer (monthly for prelim, later maybe daily)\
12. Temporal spread of birding activity
    1.  Temporal spread within day (time-of-day)\
    2.  Temporal spread within week (day-of-week)\
13. Media\
14. Number of new birders

When running the actual models, observer will be used as a random effect because all of these metrics would vary differently from observer to observer.

Post-presentation: regarding averaging national level patterns by state for some metrics, this means that means are manually calculated for states and the points plotted in the graph are only these single points per state (instead of all the raw data points).

GLMMs for birder behaviour run only for the following metrics:

-   Group birding per observer
-   Site fidelity per observer
-   Birding time per observer
-   Hotspot birding
-   Birding protocol
-   Birding distance
-   List duration
-   List length
-   Proportion of urban birding
-   Spatial coverage
-   Spatial spread (slightly different)
-   Temporal spread

These are usually driven by decision at the state level, so since the models are being run for the states individually, no need to consider district.

### Group birding (\>2 observer) per observer

```{r d01_group_po, cache=TRUE, message=FALSE}

anal_name <- "d01_group_po"

##### Final analysis: national GLMMs ####

# dataframe with empty column to populate with looped values
# total rows: product of distinct values of predictors
# taking data from all states instead of just chosen 4
data0_a <- data0_MY_d_slice_S %>% 
  tidyr::expand(nesting(MONTH, M.YEAR)) %>% 
  mutate(PRED.LINK = NA,
         SE.LINK = NA)

data_a <- data0_MY_d_slice_S %>% 
  group_by(M.YEAR, MONTH, OBSERVER.ID, SAMPLING.EVENT.IDENTIFIER) %>% 
  dplyr::summarise(GROUP.BIRDING = if_else(NUMBER.OBSERVERS > 2, 1, 0)) %>%
  ungroup()

tictoc::tic(glue("GLMM for India"))
model_a <- glmer(GROUP.BIRDING ~ M.YEAR + M.YEAR:MONTH + (1|OBSERVER.ID),
                 data = data_a, family = binomial(link = "cloglog"),
                 nAGQ = 0, control = glmerControl(optimizer = "bobyqa")) 
tictoc::toc()
# 220 sec


tictoc::tic(glue("Bootstrapped predictions for India"))
prediction <- split_par_boot(model = model_a, 
                             new_data = data0_a, 
                             new_data_string = "data0_a", 
                             mode = "extra")
tictoc::toc() # 205 min


for (i in 1:length(data0_a$MONTH)) {
  
  data0_a$PRED.LINK[i] <- median(na.omit(prediction[,i]))
  data0_a$SE.LINK[i] <- sd(na.omit(prediction[,i]))

}

data0_a <- data0_a %>% 
  mutate(PRED = clogloglink(PRED.LINK, inverse = T),
         # to transform lower bound of SE (not CI.L! think "mean +- SE")
         SE.L = clogloglink((PRED.LINK - SE.LINK), inverse = T)) %>% 
  mutate(SE = PRED - SE.L) %>% 
  mutate(CI.U = PRED + 1.96*SE,
         CI.L = PRED - 1.96*SE) %>% 
  left_join(timeline)


##### Final analysis: statewise GLMMs ####

# dataframe with empty column to populate with looped values
# total rows: product of distinct values of predictors
data0_b <- data0_MY_d_slice_S %>% 
  filter(STATE %in% anal_states[1,]) %>% 
  tidyr::expand(nesting(STATE, MONTH, M.YEAR)) %>% 
  mutate(PRED.LINK = NA,
         SE.LINK = NA,
         STATE = factor(STATE, levels = anal_states[1,])) %>% 
  arrange(STATE)


for (i in 1:4) { # for each state
  
  data0_b2 <- data0_b %>% filter(STATE == anal_states[, i])
  
  data_b <- data0_MY_d_slice_S %>% 
    filter(STATE == anal_states[, i]) %>% 
    group_by(M.YEAR, MONTH, OBSERVER.ID, SAMPLING.EVENT.IDENTIFIER) %>% 
    dplyr::summarise(GROUP.BIRDING = if_else(NUMBER.OBSERVERS > 2, 1, 0)) %>%
    ungroup() 
  
  tictoc::tic(glue("GLMM for {anal_states[, i]}"))
  model_b <- glmer(GROUP.BIRDING ~ M.YEAR + M.YEAR:MONTH + (1|OBSERVER.ID),
                   data = data_b, family = binomial(link = "cloglog"),
                   nAGQ = 0, control = glmerControl(optimizer = "bobyqa")) 
  tictoc::toc()
  
  
  tictoc::tic(glue("Bootstrapped predictions for {anal_states[, i]}"))
  prediction <- boot_conf_GLMM(model_b,
                               new_data = data0_b2,
                               new_data_string = "data0_b2",
                               nsim = 1000)
  tictoc::toc()
  
  for (j in 1:length(data0_b2$MONTH)) {
    
    data0_b2$PRED.LINK[j] <- median(na.omit(prediction[,j]))
    data0_b2$SE.LINK[j] <- sd(na.omit(prediction[,j]))
    
  }
  
  data0_b <- data0_b %>% 
    left_join(data0_b2, by = c("STATE", "MONTH", "M.YEAR")) %>% 
    transmute(MONTH = MONTH,
              M.YEAR = M.YEAR,
              STATE = STATE,
              PRED.LINK = ifelse(!is.na(PRED.LINK.y), PRED.LINK.y, PRED.LINK.x),
              SE.LINK = ifelse(!is.na(SE.LINK.y), SE.LINK.y, SE.LINK.x))
  
} 

data0_b <- data0_b %>% 
  mutate(PRED = clogloglink(PRED.LINK, inverse = T),
         # to transform lower bound of SE (not CI.L! think "mean +- SE")
         SE.L = clogloglink((PRED.LINK - SE.LINK), inverse = T)) %>% 
  mutate(SE = PRED - SE.L) %>% 
  mutate(CI.U = PRED + 1.96*SE,
         CI.L = PRED - 1.96*SE) %>% 
  left_join(timeline)

##### Saving analysis objects ####

save(data0_a, data_a, model_a, data0_b, data_b, model_b, 
     file = glue("outputs/{anal_name}.RData"))

##### Graphs ####

plot_a <- ggplot(data0_a, 
       aes(MONTH, PRED, colour = M.YEAR)) +
  labs(title = "National-level models",
       x = "Month", y = "Predicted group birding proportion") +
  geom_point(size = 2, position = position_dodge(0.5)) +
  geom_errorbar(aes(ymin = CI.L, ymax = CI.U),
                size = 1, width = 0.3, position = position_dodge(0.5)) +
  scale_colour_manual(values = covid_palette, name = "Migratory\nyear")

ggsave(filename = glue("03_wrap_figs/{anal_name}_a.png"), plot = plot_a,
       dpi = 300, width = 11, height = 6, units = "in")

plot_b <- ggplot(data0_b, 
       aes(MONTH, PRED, colour = M.YEAR)) +
  facet_wrap(~ STATE, ncol = 2, scales = "free_y") +
  labs(title = "State-level models",
       x = "Month", y = "Predicted group birding proportion") +
  geom_point(size = 3, position = position_dodge(0.5)) +
  geom_errorbar(aes(ymin = CI.L, ymax = CI.U),
                size = 1.5, width = 0.4, position = position_dodge(0.5)) +
  scale_colour_manual(values = covid_palette, name = "Migratory\nyear")

ggsave(filename = glue("03_wrap_figs/{anal_name}_b.png"), plot = plot_b,
       dpi = 300, width = 22, height = 13, units = "in")

```

### Site fidelity per observer

```{r d02_fidelity_po, cache=TRUE, message=FALSE}

anal_name <- "d02_fidelity_po"

##### Final analysis: national GLMMs ####

# dataframe with empty column to populate with looped values
# total rows: product of distinct values of predictors
# taking data from all states instead of just chosen 4
data0_a <- data0_MY_d_slice_S %>% 
  tidyr::expand(nesting(MONTH, M.YEAR)) %>% 
  mutate(PRED.LINK = NA,
         SE.LINK = NA)

data_a <- data0_MY_d_slice_S %>% 
  group_by(M.YEAR, MONTH, OBSERVER.ID) %>% 
  dplyr::summarise(NO.SITES = log(n_distinct(CELL.ID))) %>% 
  # log-transforming because Poisson GLMM won't be appropriate (zero is not a possible 
  # value in our response variable); so will run LMM instead
  ungroup() 
# not filling zeroes for M.YEAR-MONTH combos where observer had no list, because
# our aim is to see, from the people who were birding, how many sites did a birder 
# visit on average?
# number of sites is the focus here, not the individual observer (anyway a random effect)


tictoc::tic(glue("LMM for India"))
model_a <- lmer(NO.SITES ~ M.YEAR + M.YEAR:MONTH + (1|OBSERVER.ID),
                 data = data_a, 
                 control = lmerControl(optimizer = "bobyqa")) 
tictoc::toc() # 6 sec


tictoc::tic(glue("Bootstrapped predictions for India"))
prediction <- split_par_boot(model = model_a, 
                             new_data = data0_a, 
                             new_data_string = "data0_a", 
                             mode = "normal")
tictoc::toc() # 476 sec (8 min)

for (i in 1:length(data0_a$MONTH)) {
  
  data0_a$PRED.LINK[i] <- median(na.omit(prediction[,i]))
  data0_a$SE.LINK[i] <- sd(na.omit(prediction[,i]))

}

data0_a <- data0_a %>% 
  # this step doesn't change even though we log-transform prior to fitting the model
  # since the output of prediction is on log scale either way. 
  mutate(PRED = exp(PRED.LINK),
         # to transform lower bound of SE (not CI.L! think "mean +- SE")
         SE.L = exp(PRED.LINK - SE.LINK)) %>% 
  mutate(SE = PRED - SE.L) %>% 
  mutate(CI.U = PRED + 1.96*SE,
         CI.L = PRED - 1.96*SE) %>% 
  left_join(timeline)


##### Final analysis: statewise GLMMs ####

# dataframe with empty column to populate with looped values
# total rows: product of distinct values of predictors
data0_b <- data0_MY_d_slice_S %>% 
  filter(STATE %in% anal_states[1,]) %>% 
  tidyr::expand(nesting(STATE, MONTH, M.YEAR)) %>% 
  mutate(PRED.LINK = NA,
         SE.LINK = NA,
         STATE = factor(STATE, levels = anal_states[1,])) %>% 
  arrange(STATE)


for (i in 1:4) { # for each state

  data0_b2 <- data0_b %>% filter(STATE == anal_states[, i])
  
  data_b <- data0_MY_d_slice_S %>% 
    left_join(obs_mainstates, by = "OBSERVER.ID") %>% 
    filter(MAIN.STATE == anal_states[, i]) %>% 
    group_by(M.YEAR, MONTH, OBSERVER.ID) %>% 
    dplyr::summarise(NO.SITES = log(n_distinct(CELL.ID))) %>% 
    ungroup() 
  # not filling zeroes for M.YEAR-MONTH combos where observer had no list, because
  # our aim is to see, from the people who were birding, how many sites did a birder 
  # visit on average?
  # number of sites is the focus here, not the individual observer (anyway a random effect)
  
  
  tictoc::tic(glue("LMM for {anal_states[, i]}"))
  model_b <- lmer(NO.SITES ~ M.YEAR + M.YEAR:MONTH + (1|OBSERVER.ID),
                  data = data_b, 
                  control = lmerControl(optimizer = "bobyqa")) 
  tictoc::toc()
  
  
  tictoc::tic(glue("Bootstrapped predictions for {anal_states[, i]}"))
  prediction <- boot_conf_GLMM(model_b,
                               new_data = data0_b2,
                               new_data_string = "data0_b2",
                               nsim = 1000)
  tictoc::toc()
  
  for (j in 1:length(data0_b2$MONTH)) {
    
    data0_b2$PRED.LINK[j] <- median(na.omit(prediction[,j]))
    data0_b2$SE.LINK[j] <- sd(na.omit(prediction[,j]))
    
  }
  
  data0_b <- data0_b %>% 
    left_join(data0_b2, by = c("STATE", "MONTH", "M.YEAR")) %>% 
    transmute(MONTH = MONTH,
              M.YEAR = M.YEAR,
              STATE = STATE,
              PRED.LINK = ifelse(!is.na(PRED.LINK.y), PRED.LINK.y, PRED.LINK.x),
              SE.LINK = ifelse(!is.na(SE.LINK.y), SE.LINK.y, SE.LINK.x))
  
} 

data0_b <- data0_b %>% 
  mutate(PRED = exp(PRED.LINK),
         # to transform lower bound of SE (not CI.L! think "mean +- SE")
         SE.L = exp(PRED.LINK - SE.LINK)) %>% 
  mutate(SE = PRED - SE.L) %>% 
  mutate(CI.U = PRED + 1.96*SE,
         CI.L = PRED - 1.96*SE) %>% 
  left_join(timeline)

##### Saving analysis objects ####

save(data0_a, data_a, model_a, data0_b, data_b, model_b, 
     file = glue("outputs/{anal_name}.RData"))

##### Graphs ####

plot_a <- ggplot(data0_a, 
       aes(MONTH, PRED, colour = M.YEAR)) +
  labs(title = "National-level models",
       x = "Month", y = "Predicted no. of sites visited") +
  geom_point(size = 2, position = position_dodge(0.5)) +
  geom_errorbar(aes(ymin = CI.L, ymax = CI.U),
                size = 1, width = 0.3, position = position_dodge(0.5)) +
  scale_colour_manual(values = covid_palette, name = "Migratory\nyear")

ggsave(filename = glue("03_wrap_figs/{anal_name}_a.png"), plot = plot_a,
       dpi = 300, width = 11, height = 6, units = "in")

plot_b <- ggplot(data0_b, 
       aes(MONTH, PRED, colour = M.YEAR)) +
  facet_wrap(~ STATE, ncol = 2, scales = "free_y") +
  labs(title = "State-level models",
       x = "Month", y = "Predicted no. of sites visited") +
  geom_point(size = 3, position = position_dodge(0.5)) +
  geom_errorbar(aes(ymin = CI.L, ymax = CI.U),
                size = 1.5, width = 0.4, position = position_dodge(0.5)) +
  scale_colour_manual(values = covid_palette, name = "Migratory\nyear")

ggsave(filename = glue("03_wrap_figs/{anal_name}_b.png"), plot = plot_b,
       dpi = 300, width = 22, height = 13, units = "in")


```

-   At the national level, site fidelity was generally higher during the pandemic than before but mostly only around lockdown/second wave. In other months patterns closely followed pre-pandemic ones.

### Birding time per observer

```{r d03_time_po, cache=TRUE, message=FALSE}

anal_name <- "d03_time_po"

##### Final analysis: national GLMMs ####

# dataframe with empty column to populate with looped values
# total rows: product of distinct values of predictors
# taking data from all states instead of just chosen 4
data0_a <- data0_MY_d_slice_S %>% 
  tidyr::expand(nesting(MONTH, M.YEAR)) %>% 
  mutate(PRED.LINK = NA,
         SE.LINK = NA)

data_a <- data0_MY_d_slice_S %>% 
  group_by(M.YEAR, MONTH, OBSERVER.ID) %>% 
  dplyr::summarise(BIRDING.TIME = log(sum(DURATION.MINUTES))) %>% 
  # log-transforming because Poisson GLMM won't be appropriate (zero is not a possible 
  # value in our response variable); so will run LMM instead
  ungroup() 
# not filling zeroes for M.YEAR-MONTH combos where observer had no list, because
# our aim is to see, from the people who were birding, how much time was spent?



tictoc::tic(glue("LMM for India"))
model_a <- lmer(BIRDING.TIME ~ M.YEAR + M.YEAR:MONTH + (1|OBSERVER.ID),
                data = data_a, 
                control = lmerControl(optimizer = "bobyqa")) 
tictoc::toc() # 6 sec


tictoc::tic(glue("Bootstrapped predictions for India"))
prediction <- split_par_boot(model = model_a, 
                             new_data = data0_a, 
                             new_data_string = "data0_a", 
                             mode = "normal")
tictoc::toc() # 471 sec (8 min)

for (i in 1:length(data0_a$MONTH)) {
  
  data0_a$PRED.LINK[i] <- median(na.omit(prediction[,i]))
  data0_a$SE.LINK[i] <- sd(na.omit(prediction[,i]))

}

data0_a <- data0_a %>% 
  mutate(PRED = exp(PRED.LINK),
         # to transform lower bound of SE (not CI.L! think "mean +- SE")
         SE.L = exp(PRED.LINK - SE.LINK)) %>% 
  mutate(SE = PRED - SE.L) %>% 
  mutate(CI.U = PRED + 1.96*SE,
         CI.L = PRED - 1.96*SE) %>% 
  left_join(timeline)

##### Final analysis: statewise GLMMs ####

# dataframe with empty column to populate with looped values
# total rows: product of distinct values of predictors
data0_b <- data0_MY_d_slice_S %>% 
  filter(STATE %in% anal_states[1,]) %>% 
  tidyr::expand(nesting(STATE, MONTH, M.YEAR)) %>% 
  mutate(PRED.LINK = NA,
         SE.LINK = NA,
         STATE = factor(STATE, levels = anal_states[1,])) %>% 
  arrange(STATE)


for (i in 1:4) { # for each state

  data0_b2 <- data0_b %>% filter(STATE == anal_states[, i])
  
  data_b <- data0_MY_d_slice_S %>% 
    left_join(obs_mainstates, by = "OBSERVER.ID") %>% 
    filter(MAIN.STATE == anal_states[, i]) %>% 
    group_by(M.YEAR, MONTH, OBSERVER.ID) %>% 
    dplyr::summarise(BIRDING.TIME = log(sum(DURATION.MINUTES))) %>% 
    ungroup()
  # not filling zeroes for M.YEAR-MONTH combos where observer had no list, because
  # our aim is to see, from the people who were birding, how much time was spent?
  
  
  tictoc::tic(glue("LMM for {anal_states[, i]}"))
  model_b <- lmer(BIRDING.TIME ~ M.YEAR + M.YEAR:MONTH + (1|OBSERVER.ID),
                  data = data_b, 
                  control = lmerControl(optimizer = "bobyqa")) 
  tictoc::toc()
  
  
  tictoc::tic(glue("Bootstrapped predictions for {anal_states[, i]}"))
  prediction <- boot_conf_GLMM(model_b,
                               new_data = data0_b2,
                               new_data_string = "data0_b2",
                               nsim = 1000)
  tictoc::toc()
  
  for (j in 1:length(data0_b2$MONTH)) {
    
    data0_b2$PRED.LINK[j] <- median(na.omit(prediction[,j]))
    data0_b2$SE.LINK[j] <- sd(na.omit(prediction[,j]))
    
  }
  
  data0_b <- data0_b %>% 
    left_join(data0_b2, by = c("STATE", "MONTH", "M.YEAR")) %>% 
    transmute(MONTH = MONTH,
              M.YEAR = M.YEAR,
              STATE = STATE,
              PRED.LINK = ifelse(!is.na(PRED.LINK.y), PRED.LINK.y, PRED.LINK.x),
              SE.LINK = ifelse(!is.na(SE.LINK.y), SE.LINK.y, SE.LINK.x))
  
} 

data0_b <- data0_b %>% 
  mutate(PRED = exp(PRED.LINK),
         # to transform lower bound of SE (not CI.L! think "mean +- SE")
         SE.L = exp(PRED.LINK - SE.LINK)) %>% 
  mutate(SE = PRED - SE.L) %>% 
  mutate(CI.U = PRED + 1.96*SE,
         CI.L = PRED - 1.96*SE) %>% 
  left_join(timeline)

##### Saving analysis objects ####

save(data0_a, data_a, model_a, data0_b, data_b, model_b, 
     file = glue("outputs/{anal_name}.RData"))

##### Graphs ####

plot_a <- ggplot(data0_a, 
       aes(MONTH, PRED, colour = M.YEAR)) +
  labs(title = "National-level models",
       x = "Month", y = "Predicted birding time per observer") +
  geom_point(size = 2, position = position_dodge(0.5)) +
  geom_errorbar(aes(ymin = CI.L, ymax = CI.U),
                size = 1, width = 0.3, position = position_dodge(0.5)) +
  scale_colour_manual(values = covid_palette, name = "Migratory\nyear")

ggsave(filename = glue("03_wrap_figs/{anal_name}_a.png"), plot = plot_a,
       dpi = 300, width = 11, height = 6, units = "in")

plot_b <- ggplot(data0_b, 
       aes(MONTH, PRED, colour = M.YEAR)) +
  facet_wrap(~ STATE, ncol = 2, scales = "free_y") +
  labs(title = "State-level models",
       x = "Month", y = "Predicted birding time per observer") +
  geom_point(size = 3, position = position_dodge(0.5)) +
  geom_errorbar(aes(ymin = CI.L, ymax = CI.U),
                size = 1.5, width = 0.4, position = position_dodge(0.5)) +
  scale_colour_manual(values = covid_palette, name = "Migratory\nyear")

ggsave(filename = glue("03_wrap_figs/{anal_name}_b.png"), plot = plot_b,
       dpi = 300, width = 22, height = 13, units = "in")


```

-   At the national level, birding times were and are lowest during monsoon. There was no noticeable negative impact of the pandemic on monthly birding times, except in March 2020 when the pandemic was a novelty. In fact, in the monsoon months of July and August, birding times even increased slightly during the pandemic.\
-   The only other major pattern visible at the state level is in Karnataka, where birding times have increased in the months of August--October.
-   Karnataka and Assam showed a lowered birding duration around the peak months, while Kerala and Maharashtra showed no difference.

### Hotspot birding

Not "per observer", as this metric from data POV.

```{r d04_hotspot, cache=TRUE, message=FALSE}

anal_name <- "d04_hotspot"

##### Final analysis: national GLMMs ####

# dataframe with empty column to populate with looped values
# total rows: product of distinct values of predictors
# taking data from all states instead of just chosen 4
data0_a <- data0_MY_d_slice_G %>% 
  tidyr::expand(nesting(MONTH, M.YEAR)) %>% 
  mutate(PRED.LINK = NA,
         SE.LINK = NA)

data_a <- data0_MY_d_slice_G %>% 
  group_by(M.YEAR, MONTH, CELL.ID, SAMPLING.EVENT.IDENTIFIER) %>% 
  dplyr::summarise(HOTSPOT = if_else(LOCALITY.TYPE == "H", 1, 0)) %>%
  ungroup()

tictoc::tic(glue("GLMM for India"))
model_a <- glmer(HOTSPOT ~ M.YEAR + M.YEAR:MONTH + (1|CELL.ID),
                 data = data_a, family = binomial(link = "cloglog"),
                 nAGQ = 0, control = glmerControl(optimizer = "bobyqa")) 
tictoc::toc()
# 150 sec


tictoc::tic(glue("Bootstrapped predictions for India"))
prediction <- split_par_boot(model = model_a, 
                             new_data = data0_a, 
                             new_data_string = "data0_a", 
                             mode = "extra")
tictoc::toc() # 7520 sec (2h5m)


for (i in 1:length(data0_a$MONTH)) {
  
  data0_a$PRED.LINK[i] <- median(na.omit(prediction[,i]))
  data0_a$SE.LINK[i] <- sd(na.omit(prediction[,i]))

}

data0_a <- data0_a %>% 
  mutate(PRED = clogloglink(PRED.LINK, inverse = T),
         # to transform lower bound of SE (not CI.L! think "mean +- SE")
         SE.L = clogloglink((PRED.LINK - SE.LINK), inverse = T)) %>% 
  mutate(SE = PRED - SE.L) %>% 
  mutate(CI.U = PRED + 1.96*SE,
         CI.L = PRED - 1.96*SE) %>% 
  left_join(timeline)

##### Final analysis: statewise GLMMs ####

# dataframe with empty column to populate with looped values
# total rows: product of distinct values of predictors
data0_b <- data0_MY_d_slice_G %>% 
  filter(STATE %in% anal_states[1,]) %>% 
  tidyr::expand(nesting(STATE, MONTH, M.YEAR)) %>% 
  mutate(PRED.LINK = NA,
         SE.LINK = NA,
         STATE = factor(STATE, levels = anal_states[1,])) %>% 
  arrange(STATE)


for (i in 1:4) { # for each state
  
  data0_b2 <- data0_b %>% filter(STATE == anal_states[, i])
    
  data_b <- data0_MY_d_slice_G %>% 
    filter(STATE == anal_states[, i]) %>% 
    group_by(M.YEAR, MONTH, CELL.ID, SAMPLING.EVENT.IDENTIFIER) %>% 
    dplyr::summarise(HOTSPOT = if_else(LOCALITY.TYPE == "H", 1, 0)) %>%
    ungroup() 
  
  tictoc::tic(glue("GLMM for {anal_states[, i]}"))
  model_b <- glmer(HOTSPOT ~ M.YEAR + M.YEAR:MONTH + (1|CELL.ID),
                   data = data_b, family = binomial(link = "cloglog"),
                   nAGQ = 0, control = glmerControl(optimizer = "bobyqa")) 
  tictoc::toc() #


  tictoc::tic(glue("Bootstrapped predictions for {anal_states[, i]}"))
  prediction <- boot_conf_GLMM(model_b,
                               new_data = data0_b2,
                               new_data_string = "data0_b2",
                               nsim = 1000)
  tictoc::toc() #
  
  for (j in 1:length(data0_b2$MONTH)) {
    
    data0_b2$PRED.LINK[j] <- median(na.omit(prediction[,j]))
    data0_b2$SE.LINK[j] <- sd(na.omit(prediction[,j]))
    
  }
  
  data0_b <- data0_b %>% 
    left_join(data0_b2, by = c("STATE", "MONTH", "M.YEAR")) %>% 
    transmute(MONTH = MONTH,
              M.YEAR = M.YEAR,
              STATE = STATE,
              PRED.LINK = ifelse(!is.na(PRED.LINK.y), PRED.LINK.y, PRED.LINK.x),
              SE.LINK = ifelse(!is.na(SE.LINK.y), SE.LINK.y, SE.LINK.x))
  
} 

data0_b <- data0_b %>% 
  mutate(PRED = clogloglink(PRED.LINK, inverse = T),
         # to transform lower bound of SE (not CI.L! think "mean +- SE")
         SE.L = clogloglink((PRED.LINK - SE.LINK), inverse = T)) %>% 
  mutate(SE = PRED - SE.L) %>% 
  mutate(CI.U = PRED + 1.96*SE,
         CI.L = PRED - 1.96*SE) %>% 
  left_join(timeline)


##### Saving analysis objects ####

save(data0_a, data_a, model_a, data0_b, data_b, model_b, 
     file = glue("outputs/{anal_name}.RData"))

##### Graphs ####

plot_a <- ggplot(data0_a, 
                 aes(MONTH, PRED, colour = M.YEAR)) +
  labs(title = "National-level models",
       x = "Month", y = "Predicted hotspot birding proportion") +
  geom_point(size = 2, position = position_dodge(0.5)) +
  geom_errorbar(aes(ymin = CI.L, ymax = CI.U),
                size = 1, width = 0.3, position = position_dodge(0.5)) +
  scale_colour_manual(values = covid_palette, name = "Migratory\nyear")

ggsave(filename = glue("03_wrap_figs/{anal_name}_a.png"), plot = plot_a,
       dpi = 300, width = 11, height = 6, units = "in")

plot_b <- ggplot(data0_b, 
                 aes(MONTH, PRED, colour = M.YEAR)) +
  facet_wrap(~ STATE, ncol = 2, scales = "free_y") +
  labs(title = "State-level models",
       x = "Month", y = "Predicted hotspot birding proportion") +
  geom_point(size = 3, position = position_dodge(0.5)) +
  geom_errorbar(aes(ymin = CI.L, ymax = CI.U),
                size = 1.5, width = 0.4, position = position_dodge(0.5)) +
  scale_colour_manual(values = covid_palette, name = "Migratory\nyear")

ggsave(filename = glue("03_wrap_figs/{anal_name}_b.png"), plot = plot_b,
       dpi = 300, width = 22, height = 13, units = "in")

```

-   The national level saw lower hotspot birding during the lockdown/second wave months, with some spillover into the months of June and July.\
-   In Karnataka, this impact surprisingly lasted through all of 2020 but returned almost exactly to pre-COVID levels in 2021. The same to an extent in Kerala, though the difference was much less.
-   Maharashtra recovered after the peak period, while there was no effect on Assam.

### Birding protocol

Not "per observer", as this metric from data POV.

```{r d05_protocol, cache=TRUE, message=FALSE}

anal_name <- "d05_protocol"

##### Final analysis: national GLMMs ####

# dataframe with empty column to populate with looped values
# total rows: product of distinct values of predictors
# taking data from all states instead of just chosen 4
data0_a <- data0_MY_d_slice_G %>% 
  tidyr::expand(nesting(MONTH, M.YEAR)) %>% 
  mutate(PRED.LINK = NA,
         SE.LINK = NA)

data_a <- data0_MY_d_slice_G %>% 
  group_by(M.YEAR, MONTH, CELL.ID, SAMPLING.EVENT.IDENTIFIER) %>% 
  dplyr::summarise(TRAVELLING = if_else((PROTOCOL.TYPE == "Traveling" & 
                                           EFFORT.DISTANCE.KM > 0.3), 1, 0)) %>%
  ungroup()

tictoc::tic(glue("GLMM for India"))
model_a <- glmer(TRAVELLING ~ M.YEAR + M.YEAR:MONTH + (1|CELL.ID),
                 data = data_a, family = binomial(link = "cloglog"),
                 nAGQ = 0, control = glmerControl(optimizer = "bobyqa")) 
tictoc::toc() # 110 sec


tictoc::tic(glue("Bootstrapped predictions for India"))
prediction <- split_par_boot(model = model_a, 
                             new_data = data0_a, 
                             new_data_string = "data0_a", 
                             mode = "extra")
tictoc::toc() # 6245 sec (104 min)


for (i in 1:length(data0_a$MONTH)) {
  
  data0_a$PRED.LINK[i] <- median(na.omit(prediction[,i]))
  data0_a$SE.LINK[i] <- sd(na.omit(prediction[,i]))

}

data0_a <- data0_a %>% 
  mutate(PRED = clogloglink(PRED.LINK, inverse = T),
         # to transform lower bound of SE (not CI.L! think "mean +- SE")
         SE.L = clogloglink((PRED.LINK - SE.LINK), inverse = T)) %>% 
  mutate(SE = PRED - SE.L) %>% 
  mutate(CI.U = PRED + 1.96*SE,
         CI.L = PRED - 1.96*SE) %>% 
  left_join(timeline)

##### Final analysis: statewise GLMMs ####

# dataframe with empty column to populate with looped values
# total rows: product of distinct values of predictors
data0_b <- data0_MY_d_slice_G %>% 
  filter(STATE %in% anal_states[1,]) %>% 
  tidyr::expand(nesting(STATE, MONTH, M.YEAR)) %>% 
  mutate(PRED.LINK = NA,
         SE.LINK = NA,
         STATE = factor(STATE, levels = anal_states[1,])) %>% 
  arrange(STATE)


for (i in 1:4) { # for each state
  
  data0_b2 <- data0_b %>% filter(STATE == anal_states[, i])
    
  data_b <- data0_MY_d_slice_G %>% 
    filter(STATE == anal_states[, i]) %>% 
    group_by(M.YEAR, MONTH, CELL.ID, SAMPLING.EVENT.IDENTIFIER) %>% 
    dplyr::summarise(TRAVELLING = if_else((PROTOCOL.TYPE == "Traveling" & 
                                             EFFORT.DISTANCE.KM > 0.3), 1, 0)) %>%
    ungroup()
  
  tictoc::tic(glue("GLMM for {anal_states[, i]}"))
  model_b <- glmer(TRAVELLING ~ M.YEAR + M.YEAR:MONTH + (1|CELL.ID),
                   data = data_b, family = binomial(link = "cloglog"),
                   nAGQ = 0, control = glmerControl(optimizer = "bobyqa")) 
  tictoc::toc() #


  tictoc::tic(glue("Bootstrapped predictions for {anal_states[, i]}"))
  prediction <- boot_conf_GLMM(model_b,
                               new_data = data0_b2,
                               new_data_string = "data0_b2",
                               nsim = 1000)
  tictoc::toc() #


  
  for (j in 1:length(data0_b2$MONTH)) {
    
    data0_b2$PRED.LINK[j] <- median(na.omit(prediction[,j]))
    data0_b2$SE.LINK[j] <- sd(na.omit(prediction[,j]))
    
  }
  
  data0_b <- data0_b %>% 
    left_join(data0_b2, by = c("STATE", "MONTH", "M.YEAR")) %>% 
    transmute(MONTH = MONTH,
              M.YEAR = M.YEAR,
              STATE = STATE,
              PRED.LINK = ifelse(!is.na(PRED.LINK.y), PRED.LINK.y, PRED.LINK.x),
              SE.LINK = ifelse(!is.na(SE.LINK.y), SE.LINK.y, SE.LINK.x))
  
} 

data0_b <- data0_b %>% 
  mutate(PRED = clogloglink(PRED.LINK, inverse = T),
         # to transform lower bound of SE (not CI.L! think "mean +- SE")
         SE.L = clogloglink((PRED.LINK - SE.LINK), inverse = T)) %>% 
  mutate(SE = PRED - SE.L) %>% 
  mutate(CI.U = PRED + 1.96*SE,
         CI.L = PRED - 1.96*SE) %>% 
  left_join(timeline)

##### Saving analysis objects ####

save(data0_a, data_a, model_a, data0_b, data_b, model_b, 
     file = glue("outputs/{anal_name}.RData"))

##### Graphs ####

plot_a <- ggplot(data0_a, 
                 aes(MONTH, PRED, colour = M.YEAR)) +
  labs(title = "National-level models",
       x = "Month", y = "Predicted travelling birding proportion") +
  geom_point(size = 2, position = position_dodge(0.5)) +
  geom_errorbar(aes(ymin = CI.L, ymax = CI.U),
                size = 1, width = 0.3, position = position_dodge(0.5)) +
  scale_colour_manual(values = covid_palette, name = "Migratory\nyear")

ggsave(filename = glue("03_wrap_figs/{anal_name}_a.png"), plot = plot_a,
       dpi = 300, width = 11, height = 6, units = "in")

plot_b <- ggplot(data0_b, 
                 aes(MONTH, PRED, colour = M.YEAR)) +
  facet_wrap(~ STATE, ncol = 2, scales = "free_y") +
  labs(title = "State-level models",
       x = "Month", y = "Predicted travelling birding proportion") +
  geom_point(size = 3, position = position_dodge(0.5)) +
  geom_errorbar(aes(ymin = CI.L, ymax = CI.U),
                size = 1.5, width = 0.4, position = position_dodge(0.5)) +
  scale_colour_manual(values = covid_palette, name = "Migratory\nyear")

ggsave(filename = glue("03_wrap_figs/{anal_name}_b.png"), plot = plot_b,
       dpi = 300, width = 22, height = 13, units = "in")


```

-   At the national level, mobility of birders, in terms of proportion of travelling lists submitted, decreased sharply during April--May as expected, and had some spillover into June and July, but matched pre-COVID levels well in the other months of the year.

### Birding distance

Not "per observer", as this metric from data POV. Only considers travelling lists.

```{r d06_distance, cache=TRUE, message=FALSE}

anal_name <- "d06_distance"

##### Final analysis: national LMMs ####

# dataframe with empty column to populate with looped values
# total rows: product of distinct values of predictors
# taking data from all states instead of just chosen 4
data0_a <- data0_MY_d_slice_G %>% 
  tidyr::expand(nesting(MONTH, M.YEAR)) %>% 
  mutate(PRED.LINK = NA,
         SE.LINK = NA)

data_a <- data0_MY_d_slice_G %>% 
  filter(PROTOCOL.TYPE == "Traveling", !is.na(EFFORT.DISTANCE.KM), EFFORT.DISTANCE.KM > 0.3) %>% 
  group_by(M.YEAR, MONTH, CELL.ID, SAMPLING.EVENT.IDENTIFIER) %>% 
  dplyr::summarise(DISTANCE = log(EFFORT.DISTANCE.KM)) %>% 
  # because no other distribution family fits 
  ungroup() 


tictoc::tic(glue("LMM for India"))
model_a <- lmer(DISTANCE ~ M.YEAR + M.YEAR:MONTH + (1|CELL.ID),
                 data = data_a, 
                 control = lmerControl(optimizer = "bobyqa")) 
tictoc::toc() # 18 sec

tictoc::tic(glue("Bootstrapped predictions for India"))
prediction <- split_par_boot(model = model_a, 
                             new_data = data0_a, 
                             new_data_string = "data0_a", 
                             mode = "extra")
tictoc::toc() # 1603 sec (26 min)


for (i in 1:length(data0_a$MONTH)) {
  
  data0_a$PRED.LINK[i] <- median(na.omit(prediction[,i]))
  data0_a$SE.LINK[i] <- sd(na.omit(prediction[,i]))

}

data0_a <- data0_a %>% 
  # this step doesn't change even though we log-transform prior to fitting the model
  # since the output of prediction is on log scale either way. 
  mutate(PRED = exp(PRED.LINK),
         SE.L = exp(PRED.LINK - SE.LINK)) %>%
  mutate(SE = PRED - SE.L) %>% 
  mutate(CI.U = PRED + 1.96*SE,
         CI.L = PRED - 1.96*SE) %>% 
  left_join(timeline)

##### Final analysis: statewise LMMs ####

# dataframe with empty column to populate with looped values
# total rows: product of distinct values of predictors
data0_b <- data0_MY_d_slice_G %>% 
  filter(STATE %in% anal_states[1,]) %>% 
  tidyr::expand(nesting(STATE, MONTH, M.YEAR)) %>% 
  mutate(PRED.LINK = NA,
         SE.LINK = NA,
         STATE = factor(STATE, levels = anal_states[1,])) %>% 
  arrange(STATE)


for (i in 1:4) { # for each state
  
  data0_b2 <- data0_b %>% filter(STATE == anal_states[, i])
    
  data_b <- data0_MY_d_slice_G %>% 
    filter(STATE == anal_states[, i]) %>% 
    filter(PROTOCOL.TYPE == "Traveling", !is.na(EFFORT.DISTANCE.KM), EFFORT.DISTANCE.KM > 0.3) %>% 
    group_by(M.YEAR, MONTH, CELL.ID, SAMPLING.EVENT.IDENTIFIER) %>% 
    dplyr::summarise(DISTANCE = log(EFFORT.DISTANCE.KM)) %>% 
    # because no other distribution family fits 
    ungroup() 
  
  tictoc::tic(glue("LMM for {anal_states[, i]}"))
  model_b <- lmer(DISTANCE ~ M.YEAR + M.YEAR:MONTH + (1|CELL.ID),
                   data = data_b, 
                   control = lmerControl(optimizer = "bobyqa")) 
  tictoc::toc() #

  
  tictoc::tic(glue("Bootstrapped predictions for {anal_states[, i]}"))
  prediction <- boot_conf_GLMM(model_b,
                               new_data = data0_b2,
                               new_data_string = "data0_b2",
                               nsim = 1000)
  tictoc::toc() #


  
  for (j in 1:length(data0_b2$MONTH)) {
    
    data0_b2$PRED.LINK[j] <- median(na.omit(prediction[,j]))
    data0_b2$SE.LINK[j] <- sd(na.omit(prediction[,j]))
    
  }
  
  data0_b <- data0_b %>% 
    left_join(data0_b2, by = c("STATE", "MONTH", "M.YEAR")) %>% 
    transmute(MONTH = MONTH,
              M.YEAR = M.YEAR,
              STATE = STATE,
              PRED.LINK = ifelse(!is.na(PRED.LINK.y), PRED.LINK.y, PRED.LINK.x),
              SE.LINK = ifelse(!is.na(SE.LINK.y), SE.LINK.y, SE.LINK.x))
  
} 

data0_b <- data0_b %>% 
  mutate(PRED = exp(PRED.LINK),
         SE.L = exp(PRED.LINK - SE.LINK)) %>% 
  mutate(SE = PRED - SE.L) %>% 
  mutate(CI.U = PRED + 1.96*SE,
         CI.L = PRED - 1.96*SE) %>% 
  left_join(timeline)



##### Saving analysis objects ####

save(data0_a, data_a, model_a, data0_b, data_b, model_b, 
     file = glue("outputs/{anal_name}.RData"))

##### Graphs ####

plot_a <- ggplot(data0_a, 
                 aes(MONTH, PRED, colour = M.YEAR)) +
  labs(title = "National-level models",
       x = "Month", y = "Predicted birding distance") +
  geom_point(size = 2, position = position_dodge(0.5)) +
  geom_errorbar(aes(ymin = CI.L, ymax = CI.U),
                size = 1, width = 0.3, position = position_dodge(0.5)) +
  scale_colour_manual(values = covid_palette, name = "Migratory\nyear")

ggsave(filename = glue("03_wrap_figs/{anal_name}_a.png"), plot = plot_a,
       dpi = 300, width = 11, height = 6, units = "in")

plot_b <- ggplot(data0_b, 
                 aes(MONTH, PRED, colour = M.YEAR)) +
  facet_wrap(~ STATE, ncol = 2, scales = "free_y") +
  labs(title = "State-level models",
       x = "Month", y = "Predicted birding distance") +
  geom_point(size = 3, position = position_dodge(0.5)) +
  geom_errorbar(aes(ymin = CI.L, ymax = CI.U),
                size = 1.5, width = 0.4, position = position_dodge(0.5)) +
  scale_colour_manual(values = covid_palette, name = "Migratory\nyear")

ggsave(filename = glue("03_wrap_figs/{anal_name}_b.png"), plot = plot_b,
       dpi = 300, width = 22, height = 13, units = "in")


```

-   At the national level, checklist distances were highest during summer and winter before the pandemic. During the pandemic, distances remained fairly similar for the winter months of October--December, but were drastically lower during the summer months of April and May, which coincided with the lockdown/second wave.\
-   Overall, this metric was not affected as much as others. Karnataka and Kerala showed some brief declines, but overall patterns are rather irregular, so nothing major. Maharashtra has shown a consistent decline since the start of the pandemic till now.

### List duration

Not "per observer", as this metric from data POV.

```{r d07_duration, cache=TRUE, message=FALSE}

anal_name <- "d07_duration"

##### Final analysis: national LMMs ####

# dataframe with empty column to populate with looped values
# total rows: product of distinct values of predictors
# taking data from all states instead of just chosen 4
data0_a <- data0_MY_d_slice_G %>% 
  tidyr::expand(nesting(MONTH, M.YEAR)) %>% 
  mutate(PRED.LINK = NA,
         SE.LINK = NA)

data_a <- data0_MY_d_slice_G %>% 
  group_by(M.YEAR, MONTH, CELL.ID, SAMPLING.EVENT.IDENTIFIER) %>% 
  dplyr::summarise(DURATION = log(DURATION.MINUTES)) %>% 
  # because no other distribution family fits 
  ungroup() 


tictoc::tic(glue("LMM for India"))
model_a <- lmer(DURATION ~ M.YEAR + M.YEAR:MONTH + (1|CELL.ID),
                 data = data_a, 
                 control = lmerControl(optimizer = "bobyqa")) 
tictoc::toc() # 35 sec

tictoc::tic(glue("Bootstrapped predictions for India"))
prediction <- split_par_boot(model = model_a, 
                             new_data = data0_a, 
                             new_data_string = "data0_a", 
                             mode = "extra")
tictoc::toc() # 2937 sec (49 min)


for (i in 1:length(data0_a$MONTH)) {
  
  data0_a$PRED.LINK[i] <- median(na.omit(prediction[,i]))
  data0_a$SE.LINK[i] <- sd(na.omit(prediction[,i]))

}

data0_a <- data0_a %>% 
  # this step doesn't change even though we log-transform prior to fitting the model
  # since the output of prediction is on log scale either way. 
  mutate(PRED = exp(PRED.LINK),
         SE.L = exp(PRED.LINK - SE.LINK)) %>%
  mutate(SE = PRED - SE.L) %>% 
  mutate(CI.U = PRED + 1.96*SE,
         CI.L = PRED - 1.96*SE) %>% 
  left_join(timeline)


##### Final analysis: statewise LMMs ####

# dataframe with empty column to populate with looped values
# total rows: product of distinct values of predictors
data0_b <- data0_MY_d_slice_G %>% 
  filter(STATE %in% anal_states[1,]) %>% 
  tidyr::expand(nesting(STATE, MONTH, M.YEAR)) %>% 
  mutate(PRED.LINK = NA,
         SE.LINK = NA,
         STATE = factor(STATE, levels = anal_states[1,])) %>% 
  arrange(STATE)


for (i in 1:4) { # for each state
  
  data0_b2 <- data0_b %>% filter(STATE == anal_states[, i])
    
  data_b <- data0_MY_d_slice_G %>% 
    filter(STATE == anal_states[, i]) %>% 
    group_by(M.YEAR, MONTH, CELL.ID, SAMPLING.EVENT.IDENTIFIER) %>% 
    dplyr::summarise(DURATION = log(DURATION.MINUTES)) %>% 
    # because no other distribution family fits 
    ungroup() 
  
  tictoc::tic(glue("LMM for {anal_states[, i]}"))
  model_b <- lmer(DURATION ~ M.YEAR + M.YEAR:MONTH + (1|CELL.ID),
                   data = data_b, 
                   control = lmerControl(optimizer = "bobyqa")) 
  tictoc::toc() #

  
  tictoc::tic(glue("Bootstrapped predictions for {anal_states[, i]}"))
  prediction <- boot_conf_GLMM(model_b,
                               new_data = data0_b2,
                               new_data_string = "data0_b2",
                               nsim = 1000)
  tictoc::toc() #


  
  for (j in 1:length(data0_b2$MONTH)) {
    
    data0_b2$PRED.LINK[j] <- median(na.omit(prediction[,j]))
    data0_b2$SE.LINK[j] <- sd(na.omit(prediction[,j]))
    
  }
  
  data0_b <- data0_b %>% 
    left_join(data0_b2, by = c("STATE", "MONTH", "M.YEAR")) %>% 
    transmute(MONTH = MONTH,
              M.YEAR = M.YEAR,
              STATE = STATE,
              PRED.LINK = ifelse(!is.na(PRED.LINK.y), PRED.LINK.y, PRED.LINK.x),
              SE.LINK = ifelse(!is.na(SE.LINK.y), SE.LINK.y, SE.LINK.x))
  
} 

data0_b <- data0_b %>% 
  mutate(PRED = exp(PRED.LINK),
         SE.L = exp(PRED.LINK - SE.LINK)) %>% 
  mutate(SE = PRED - SE.L) %>% 
  mutate(CI.U = PRED + 1.96*SE,
         CI.L = PRED - 1.96*SE) %>% 
  left_join(timeline)


##### Saving analysis objects ####

save(data0_a, data_a, model_a, data0_b, data_b, model_b, 
     file = glue("outputs/{anal_name}.RData"))

##### Graphs ####

plot_a <- ggplot(data0_a, 
                 aes(MONTH, PRED, colour = M.YEAR)) +
  labs(title = "National-level models",
       x = "Month", y = "Predicted list duration") +
  geom_point(size = 2, position = position_dodge(0.5)) +
  geom_errorbar(aes(ymin = CI.L, ymax = CI.U),
                size = 1, width = 0.3, position = position_dodge(0.5)) +
  scale_colour_manual(values = covid_palette, name = "Migratory\nyear")

ggsave(filename = glue("03_wrap_figs/{anal_name}_a.png"), plot = plot_a,
       dpi = 300, width = 11, height = 6, units = "in")

plot_b <- ggplot(data0_b, 
                 aes(MONTH, PRED, colour = M.YEAR)) +
  facet_wrap(~ STATE, ncol = 2, scales = "free_y") +
  labs(title = "State-level models",
       x = "Month", y = "Predicted list duration") +
  geom_point(size = 3, position = position_dodge(0.5)) +
  geom_errorbar(aes(ymin = CI.L, ymax = CI.U),
                size = 1.5, width = 0.4, position = position_dodge(0.5)) +
  scale_colour_manual(values = covid_palette, name = "Migratory\nyear")

ggsave(filename = glue("03_wrap_figs/{anal_name}_b.png"), plot = plot_b,
       dpi = 300, width = 22, height = 13, units = "in")

```

-   In normal circumstances, checklists become longer in the winter, and shorter in the monsoon. The only notable change during the pandemic at the national level was low checklist duration in April--June, due to the national lockdown/second wave.\
-   A point of interest is that the average checklist duration varied greatly between states. Among the 4 compared here, Kerala on average had shortest lists, followed by Karnataka and then Maharashtra.\
-   Patterns somewhat similar to those of birding distance. Generally, briefly reduced during the peak months.

### List length

Not "per observer", as this metric from data POV.

```{r d08_length, cache=TRUE, message=FALSE}

anal_name <- "d08_length"

##### Final analysis: national GLMMs ####

# dataframe with empty column to populate with looped values
# total rows: product of distinct values of predictors
# taking data from all states instead of just chosen 4
data0_a <- data0_MY_d_slice_G %>% 
  tidyr::expand(nesting(MONTH, M.YEAR)) %>% 
  mutate(PRED.LINK = NA,
         SE.LINK = NA)

data_a <- data0_MY_d_slice_G %>% 
  group_by(M.YEAR, MONTH, CELL.ID, SAMPLING.EVENT.IDENTIFIER) %>% 
  dplyr::summarise(LENGTH = NO.SP) %>%
  ungroup()

tictoc::tic(glue("GLMM for India"))
model_a <- glmer(LENGTH ~ M.YEAR + M.YEAR:MONTH + (1|CELL.ID),
                 data = data_a, family = poisson,
                 nAGQ = 0, control = glmerControl(optimizer = "bobyqa")) 
tictoc::toc() # 82 sec


tictoc::tic(glue("Bootstrapped predictions for India"))
prediction <- split_par_boot(model = model_a, 
                             new_data = data0_a, 
                             new_data_string = "data0_a", 
                             mode = "extra")
tictoc::toc() # 5059 sec (84 mins)


for (i in 1:length(data0_a$MONTH)) {
  
  data0_a$PRED.LINK[i] <- median(na.omit(prediction[,i]))
  data0_a$SE.LINK[i] <- sd(na.omit(prediction[,i]))

}

data0_a <- data0_a %>% 
  mutate(PRED = exp(PRED.LINK),
         SE.L = exp(PRED.LINK - SE.LINK)) %>% 
  mutate(SE = PRED - SE.L) %>% 
  mutate(CI.U = PRED + 1.96*SE,
         CI.L = PRED - 1.96*SE) %>% 
  left_join(timeline)


##### Final analysis: statewise GLMMs ####

# dataframe with empty column to populate with looped values
# total rows: product of distinct values of predictors
data0_b <- data0_MY_d_slice_G %>% 
  filter(STATE %in% anal_states[1,]) %>% 
  tidyr::expand(nesting(STATE, MONTH, M.YEAR)) %>% 
  mutate(PRED.LINK = NA,
         SE.LINK = NA,
         STATE = factor(STATE, levels = anal_states[1,])) %>% 
  arrange(STATE)


for (i in 1:4) { # for each state
  
  data0_b2 <- data0_b %>% filter(STATE == anal_states[, i])
    
  data_b <- data0_MY_d_slice_G %>% 
    filter(STATE == anal_states[, i]) %>% 
    group_by(M.YEAR, MONTH, CELL.ID, SAMPLING.EVENT.IDENTIFIER) %>% 
    dplyr::summarise(LENGTH = NO.SP) %>%
    ungroup()
  
  tictoc::tic(glue("GLMM for {anal_states[, i]}"))
  model_b <- glmer(LENGTH ~ M.YEAR + M.YEAR:MONTH + (1|CELL.ID),
                   data = data_b, family = poisson,
                   nAGQ = 0, control = glmerControl(optimizer = "bobyqa")) 
  tictoc::toc() #

  
  tictoc::tic(glue("Bootstrapped predictions for {anal_states[, i]}"))
  prediction <- boot_conf_GLMM(model_b,
                               new_data = data0_b2,
                               new_data_string = "data0_b2",
                               nsim = 1000)
  tictoc::toc() #


  
  for (j in 1:length(data0_b2$MONTH)) {
    
    data0_b2$PRED.LINK[j] <- median(na.omit(prediction[,j]))
    data0_b2$SE.LINK[j] <- sd(na.omit(prediction[,j]))
    
  }
  
  data0_b <- data0_b %>% 
    left_join(data0_b2, by = c("STATE", "MONTH", "M.YEAR")) %>% 
    transmute(MONTH = MONTH,
              M.YEAR = M.YEAR,
              STATE = STATE,
              PRED.LINK = ifelse(!is.na(PRED.LINK.y), PRED.LINK.y, PRED.LINK.x),
              SE.LINK = ifelse(!is.na(SE.LINK.y), SE.LINK.y, SE.LINK.x))
  
} 

data0_b <- data0_b %>% 
  mutate(PRED = exp(PRED.LINK),
         SE.L = exp(PRED.LINK - SE.LINK)) %>% 
  mutate(SE = PRED - SE.L) %>% 
  mutate(CI.U = PRED + 1.96*SE,
         CI.L = PRED - 1.96*SE) %>% 
  left_join(timeline)

##### Saving analysis objects ####

save(data0_a, data_a, model_a, data0_b, data_b, model_b, 
     file = glue("outputs/{anal_name}.RData"))

##### Graphs ####

plot_a <- ggplot(data0_a, 
                 aes(MONTH, PRED, colour = M.YEAR)) +
  labs(title = "National-level models",
       x = "Month", y = "Predicted list length") +
  geom_point(size = 2, position = position_dodge(0.5)) +
  geom_errorbar(aes(ymin = CI.L, ymax = CI.U),
                size = 1, width = 0.3, position = position_dodge(0.5)) +
  scale_colour_manual(values = covid_palette, name = "Migratory\nyear")

ggsave(filename = glue("03_wrap_figs/{anal_name}_a.png"), plot = plot_a,
       dpi = 300, width = 11, height = 6, units = "in")

plot_b <- ggplot(data0_b, 
                 aes(MONTH, PRED, colour = M.YEAR)) +
  facet_wrap(~ STATE, ncol = 2, scales = "free_y") +
  labs(title = "State-level models",
       x = "Month", y = "Predicted list length") +
  geom_point(size = 3, position = position_dodge(0.5)) +
  geom_errorbar(aes(ymin = CI.L, ymax = CI.U),
                size = 1.5, width = 0.4, position = position_dodge(0.5)) +
  scale_colour_manual(values = covid_palette, name = "Migratory\nyear")

ggsave(filename = glue("03_wrap_figs/{anal_name}_b.png"), plot = plot_b,
       dpi = 300, width = 22, height = 13, units = "in")

```

-   Overall, slight decrease during the peak period.\
-   Kerala didn't show any change at all.\
-   The peak months brought average list length in other states to around 10-11 species, which in Kerala's case already used to be the case (shorter lists).

### Spatial spread and coverage

1.  Urban:non-urban ratio in birding effort
    -   Proportion of lists that are urban per grid cell\
    -   Proportion of lists that are urban per grid cell GLMM\
2.  Spatial coverage (min. 10 lists per grid cell)
    -   Proportion of total cells in country/state covered across months
    -   Proportion of total cells in country/state covered across months GLMM\
3.  Spatial spread/evenness (25kmx25km cells; across 9 months) Large spatial and temporal scale---no STATE or MONTH/M.YEAR in question.
    -   Raw change in no. of lists per district
    -   Proportional change in no. of lists per district (only declines)
    -   Raw change in grid coverage per district
    -   Proportional change in grid coverage per district (only declines)

```{r d09a_s_UNU, cache=TRUE, message=FALSE}

anal_name <- "d09a_s_UNU"

# https://github.com/lme4/lme4/issues/281
# Issue with high number of zeroes (or hence low proportion values) and back-transformation of linear variable without accounting for random variation (Jensen's inequality effects)
# So, need to include random effects in prediction, and need to predict at response scale.

##### Final analysis: national GLMMs ####

data0_a <- data0_MY_d_slice_G %>% 
  tidyr::expand(nesting(MONTH, M.YEAR)) %>% 
  mutate(PRED.LINK = NA,
         SE.LINK = NA)

data_a <- data0_MY_d_slice_G %>% 
  distinct(M.YEAR, MONTH, COUNTY, CELL.ID, SAMPLING.EVENT.IDENTIFIER, URBAN) %>%
  ungroup()

county_cell <- data_a %>% distinct(COUNTY, CELL.ID)

tictoc::tic(glue("GLMM for India"))
model_a <- glmer(URBAN ~ M.YEAR + M.YEAR:MONTH + (1|COUNTY/CELL.ID),
                 data = data_a, family = binomial(link = "cloglog"),
                 nAGQ = 0, control = glmerControl(optimizer = "bobyqa")) 
tictoc::toc() # 924 sec (15 min)


tictoc::tic(glue("Bootstrapped predictions for India"))
prediction <- split_par_boot(model = model_a, 
                             new_data = data0_a, 
                             new_data_string = "data0_a", 
                             mode = "extra")
tictoc::toc() # 32920 sec (9.14 h)


for (i in 1:length(data0_a$MONTH)) {
  
  data0_a$PRED.LINK[i] <- median(na.omit(prediction[,i]))
  data0_a$SE.LINK[i] <- sd(na.omit(prediction[,i]))

}

data0_a <- data0_a %>% 
  mutate(PRED = clogloglink(PRED.LINK, inverse = T),
         # to transform lower bound of SE (not CI.L! think "mean +- SE")
         SE.L = clogloglink((PRED.LINK - SE.LINK), inverse = T)) %>% 
  mutate(SE = PRED - SE.L) %>% 
  mutate(CI.U = PRED + 1.96*SE,
         CI.L = PRED - 1.96*SE) %>% 
  left_join(timeline)


##### Final analysis: national GLMMs (without nested random effect) ####

data0_b <- data0_MY_d_slice_G %>% 
  tidyr::expand(nesting(MONTH, M.YEAR, CELL.ID)) %>% 
  mutate(PRED.LINK = NA,
         SE.LINK = NA)

data_b <- data0_MY_d_slice_G %>% 
  distinct(M.YEAR, MONTH, CELL.ID, SAMPLING.EVENT.IDENTIFIER, URBAN) %>%
  ungroup()

tictoc::tic(glue("GLMM for India"))
model_b <- glmer(URBAN ~ M.YEAR + M.YEAR:MONTH + (1|CELL.ID),
                 data = data_b, family = binomial(link = "cloglog"),
                 nAGQ = 0, control = glmerControl(optimizer = "bobyqa")) 
tictoc::toc() # 303 sec (5 min)


tictoc::tic(glue("Bootstrapped predictions for India"))
prediction <- split_par_boot(model = model_b, 
                             new_data = data0_b, 
                             new_data_string = "data0_b", 
                             mode = "extra",
                             re_form = ~ (1|CELL.ID),
                             pred_type = "response")
tictoc::toc() # 9028 sec (150 min)


for (i in 1:length(data0_b$MONTH)) {
  
  data0_b$PRED.LINK[i] <- median(na.omit(prediction[,i]))
  data0_b$SE.LINK[i] <- sd(na.omit(prediction[,i]))

}

data0_b <- data0_b %>% 
  mutate(PRED = PRED.LINK,
         SE = SE.LINK) %>% 
  mutate(CI.L = PRED - 1.96*SE,
         CI.U = PRED + 1.96*SE) %>% 
  left_join(timeline)


##### Saving analysis objects ####

save(data0_a, data_a, model_a, data0_b, data_b, model_b, 
     file = glue("outputs/{anal_name}.RData"))

##### Graphs ####

plot_a <- ggplot(data0_a, 
                 aes(MONTH, PRED, colour = M.YEAR)) +
  labs(title = "National-level models",
       x = "Month", y = "Predicted urban birding proportion") +
  geom_point(size = 2, position = position_dodge(0.5)) +
  geom_errorbar(aes(ymin = CI.L, ymax = CI.U),
                size = 1, width = 0.3, position = position_dodge(0.5)) +
  scale_colour_manual(values = covid_palette, name = "Migratory\nyear")

ggsave(filename = glue("03_wrap_figs/{anal_name}_a.png"), plot = plot_a,
       dpi = 300, width = 11, height = 6, units = "in")

# plot_b <- ggplot(data0_b, 
#                  aes(MONTH, PRED, colour = M.YEAR)) +
#   facet_wrap(~ STATE, ncol = 2, scales = "free_y") +
#   labs(title = "State-level models",
#        x = "Month", y = "Predicted list length") +
#   geom_point(size = 3, position = position_dodge(0.5)) +
#   geom_errorbar(aes(ymin = CI.L, ymax = CI.U),
#                 size = 1.5, width = 0.4, position = position_dodge(0.5)) +
#   scale_colour_manual(values = covid_palette, name = "Migratory\nyear")

plot_b <- ggplot(data0_b, 
                 aes(MONTH, PRED, colour = M.YEAR)) +
  labs(title = "National-level models (without nested random effects)",
       x = "Month", y = "Predicted urban birding proportion") +
  geom_point(size = 2, position = position_dodge(0.5)) +
  geom_errorbar(aes(ymin = CI.L, ymax = CI.U),
                size = 1, width = 0.3, position = position_dodge(0.5)) +
  scale_colour_manual(values = covid_palette, name = "Migratory\nyear")

ggsave(filename = glue("03_wrap_figs/{anal_name}_b.png"), plot = plot_b,
       dpi = 300, width = 11, height = 6, units = "in")

```

```{r d09b_s_cover, cache=TRUE, message=FALSE}

anal_name <- "d09b_s_cover"

##### Final analysis: national GLMMs ####

data0_a <- data0_MY_d_slice_G %>% 
  tidyr::expand(nesting(MONTH, M.YEAR)) %>% 
  mutate(PRED.LINK = NA,
         SE.LINK = NA)

data_a <- data0_MY_d_slice_G %>% 
  group_by(M.YEAR, MONTH, CELL.ID) %>% 
  dplyr::summarise(COVERED = if_else(n_distinct(SAMPLING.EVENT.IDENTIFIER) >= 5, 1, 0)) %>% 
  # threshold to consider cell "covered"
  group_by(M.YEAR, MONTH) %>% 
  complete(CELL.ID = gridmapg1_IN$CELL.ID, fill = list(COVERED = 0)) %>% 
  ungroup()

tictoc::tic(glue("GLMM for India"))
model_a <- glmer(COVERED ~ M.YEAR + M.YEAR:MONTH + (1|CELL.ID),
                 data = data_a, family = binomial(link = "cloglog"),
                 nAGQ = 0, control = glmerControl(optimizer = "bobyqa")) 
tictoc::toc() # 114 sec


tictoc::tic(glue("Bootstrapped predictions for India"))
prediction <- split_par_boot(model = model_a, 
                             new_data = data0_a, 
                             new_data_string = "data0_a")
tictoc::toc() # 2494 sec (41 min)


for (i in 1:length(data0_a$MONTH)) {
  
  data0_a$PRED.LINK[i] <- median(na.omit(prediction[,i]))
  data0_a$SE.LINK[i] <- sd(na.omit(prediction[,i]))

}

data0_a <- data0_a %>% 
  mutate(PRED = clogloglink(PRED.LINK, inverse = T),
         # to transform lower bound of SE (not CI.L! think "mean +- SE")
         SE.L = clogloglink((PRED.LINK - SE.LINK), inverse = T)) %>% 
  mutate(SE = PRED - SE.L) %>% 
  mutate(CI.U = PRED + 1.96*SE,
         CI.L = PRED - 1.96*SE) %>% 
  left_join(timeline)

##### Final analysis: statewise GLMMs ####

# dataframe with empty column to populate with looped values
# total rows: product of distinct values of predictors
data0_b <- data0_MY_d_slice_G %>% 
  filter(STATE %in% anal_states[1,]) %>% 
  tidyr::expand(nesting(STATE, MONTH, M.YEAR)) %>% 
  mutate(PRED.LINK = NA,
         SE.LINK = NA,
         STATE = factor(STATE, levels = anal_states[1,])) %>% 
  arrange(STATE)


for (i in 1:4) { # for each state
  
  data0_b2 <- data0_b %>% filter(STATE == anal_states[, i])
  gridmapg1_ST_temp <- gridmapg1_ST %>% filter(STATE == anal_states[, i])
    
  data_b <- data0_MY_d_slice_G %>% 
    filter(STATE == anal_states[, i]) %>% 
    group_by(M.YEAR, MONTH, CELL.ID) %>% 
    dplyr::summarise(COVERED = if_else(n_distinct(SAMPLING.EVENT.IDENTIFIER) >= 5, 1, 0)) %>% 
    # threshold to consider cell "covered"
    group_by(M.YEAR, MONTH) %>% 
    complete(CELL.ID = gridmapg1_ST_temp$CELL.ID, fill = list(COVERED = 0)) %>% 
    ungroup()
  
  tictoc::tic(glue("GLMM for {anal_states[, i]}"))
  model_b <- glmer(COVERED ~ M.YEAR + M.YEAR:MONTH + (1|CELL.ID),
                   data = data_b, family = binomial(link = "cloglog"),
                   nAGQ = 0, control = glmerControl(optimizer = "bobyqa")) 
  tictoc::toc() #


  tictoc::tic(glue("Bootstrapped predictions for {anal_states[, i]}"))
  prediction <- boot_conf_GLMM(model_b,
                               new_data = data0_b2,
                               new_data_string = "data0_b2",
                               nsim = 1000)
  tictoc::toc() #
  
  
  for (j in 1:length(data0_b2$MONTH)) {
    
    data0_b2$PRED.LINK[j] <- median(na.omit(prediction[,j]))
    data0_b2$SE.LINK[j] <- sd(na.omit(prediction[,j]))
    
  }
  
  data0_b <- data0_b %>% 
    left_join(data0_b2, by = c("STATE", "MONTH", "M.YEAR")) %>% 
    transmute(MONTH = MONTH,
              M.YEAR = M.YEAR,
              STATE = STATE,
              PRED.LINK = ifelse(!is.na(PRED.LINK.y), PRED.LINK.y, PRED.LINK.x),
              SE.LINK = ifelse(!is.na(SE.LINK.y), SE.LINK.y, SE.LINK.x))
  
} 

data0_b <- data0_b %>% 
  mutate(PRED = clogloglink(PRED.LINK, inverse = T),
         # to transform lower bound of SE (not CI.L! think "mean +- SE")
         SE.L = clogloglink((PRED.LINK - SE.LINK), inverse = T)) %>% 
  mutate(SE = PRED - SE.L) %>% 
  mutate(CI.U = PRED + 1.96*SE,
         CI.L = PRED - 1.96*SE) %>% 
  left_join(timeline)


##### Saving analysis objects ####

save(data0_a, data_a, model_a, data0_b, data_b, model_b, 
     file = glue("outputs/{anal_name}.RData"))

##### Graphs ####

plot_a <- ggplot(data0_a, 
                 aes(MONTH, PRED, colour = M.YEAR)) +
  labs(title = "National-level models",
       x = "Month", y = "Predicted proportion of grid cells covered") +
  geom_point(size = 2, position = position_dodge(0.5)) +
  geom_errorbar(aes(ymin = CI.L, ymax = CI.U),
                size = 1, width = 0.3, position = position_dodge(0.5)) +
  scale_colour_manual(values = covid_palette, name = "Migratory\nyear")

ggsave(filename = glue("03_wrap_figs/{anal_name}_a.png"), plot = plot_a,
       dpi = 300, width = 11, height = 6, units = "in")

plot_b <- ggplot(data0_b, 
                 aes(MONTH, PRED, colour = M.YEAR)) +
  facet_wrap(~ STATE, ncol = 2, scales = "free_y") +
  labs(title = "State-level models",
       x = "Month", y = "Predicted proportion of grid cells covered") +
  geom_point(size = 3, position = position_dodge(0.5)) +
  geom_errorbar(aes(ymin = CI.L, ymax = CI.U),
                size = 1.5, width = 0.4, position = position_dodge(0.5)) +
  scale_colour_manual(values = covid_palette, name = "Migratory\nyear")

ggsave(filename = glue("03_wrap_figs/{anal_name}_b.png"), plot = plot_b,
       dpi = 300, width = 22, height = 13, units = "in")

```

For spread, we will not consider change in number or proportion of lists per grid cells because there will be too much noise at that fine a scale. Here, districts provide a nice compromise: large enough to track change, small enough to inform us about local patterns. For grid coverage, only those districts that have a minimum of 5 grid cells will be considered.

```{r d09c_s_spread, cache=TRUE, message=FALSE}

anal_name <- "d09c_s_spread"

##### Preparing data ####

gridmapg1_IN <- gridmapg1_IN %>% 
  # setting CRS for join in next step
  st_set_crs(value = st_crs(districtmap))

# creating object linking grid cells to districts
grid_dist_base0 <- districtmap %>% 
  st_as_sf() %>% 
  dplyr::select(dtname) %>% 
  rename(DISTRICT.NAME = dtname) %>% 
# some districts have two different rows (two different polygons) so need to combine
# them into one polygon
  group_by(DISTRICT.NAME) %>% 
  summarise() # dplyr-sf magic :) 
# https://gis.stackexchange.com/questions/421651/merging-two-multipolygon-shapefiles-and-removing-one-of-overlapping-polygons-usi

grid_dist_base <- grid_dist_base0 %>% st_join(gridmapg1_IN)
# losing some districts and grid cells, but doesn't matter. 
# Will explore patterns with existing.

# for number of lists where no threshold for district consideration
set.seed(31)
grid_dist_links1 <- grid_dist_base %>% 
  st_drop_geometry() %>% 
  # Ensuring that a grid cell is only linked with one district
  group_by(CELL.ID) %>% 
  slice_sample() %>% 
  group_by(DISTRICT.NAME) %>% 
  mutate(NO.CELLS.TOT = n_distinct(CELL.ID)) %>% 
  ungroup()

grid_dist_links <- grid_dist_links1 %>% 
  # considering only districts with at least 5 grid cells for grid coverage
  filter(NO.CELLS.TOT >= 5)

grid_dist1 <- grid_dist_base %>% right_join(grid_dist_links1)
grid_dist <- grid_dist_base %>% right_join(grid_dist_links)


temp01 <- data0_MY_d_slice_G %>% 
  # combining the two DUR years
  mutate(COVID = case_when(M.YEAR == 2018 ~ "BEF",
                           M.YEAR %in% 2019:2020 ~ "DUR",
                           M.YEAR == 2021 ~ "AFT")) %>% 
  mutate(COVID = factor(COVID, levels = c("BEF", "DUR", "AFT"))) %>% 
  dplyr::select(-DISTRICT) %>% # removing to avoid confusion 
  inner_join(grid_dist1) 

temp0 <- data0_MY_d_slice_G %>% 
  # combining the two DUR years
  mutate(COVID = case_when(M.YEAR == 2018 ~ "BEF",
                           M.YEAR %in% 2019:2020 ~ "DUR",
                           M.YEAR == 2021 ~ "AFT")) %>% 
  mutate(COVID = factor(COVID, levels = c("BEF", "DUR", "AFT"))) %>% 
  dplyr::select(-DISTRICT) %>% # removing to avoid confusion
  inner_join(grid_dist)

dist_cons1 <- temp01 %>% distinct(DISTRICT.NAME, NO.CELLS.TOT) %>% arrange(DISTRICT.NAME)
dist_cons <- temp0 %>% distinct(DISTRICT.NAME, NO.CELLS.TOT) %>% arrange(DISTRICT.NAME)


temp1 <- temp0 %>% 
  # average gridcov across two DUR years
  group_by(M.YEAR, DISTRICT.NAME, NO.CELLS.TOT) %>% 
  summarise(NO.CELLS = n_distinct(CELL.ID),
            GRID.COV = 100*NO.CELLS/min(NO.CELLS.TOT),
            COVID = COVID) %>% 
  group_by(COVID, DISTRICT.NAME, NO.CELLS.TOT) %>% 
  summarise(GRID.COV = mean(GRID.COV)) %>% 
  ungroup() %>% 
  # only considering districts covered at least once in the four years
  complete(COVID, 
           DISTRICT.NAME = dist_cons$DISTRICT.NAME,
           fill = list(GRID.COV = 0)) %>% 
  dplyr::select(-NO.CELLS.TOT) %>% 
  left_join(dist_cons)

# for grid coverage per district with threshold
temp2 <- temp0 %>% 
  # average gridcov across two DUR years
  group_by(M.YEAR, DISTRICT.NAME, NO.CELLS.TOT, CELL.ID) %>% 
  summarise(CELL.LISTS = n_distinct(GROUP.ID),
            COVID = COVID) %>% 
  # threshold of 5 lists in a grid cell (per year) for the cell to be considered "covered"
  filter(CELL.LISTS >= 5) %>% 
  summarise(NO.CELLS = n_distinct(CELL.ID),
            GRID.COV.T = 100*NO.CELLS/min(NO.CELLS.TOT),
            COVID = COVID) %>% 
  group_by(COVID, DISTRICT.NAME, NO.CELLS.TOT) %>% 
  summarise(GRID.COV.T = mean(GRID.COV.T)) %>% 
  ungroup() %>% 
  # only considering districts covered at least once in the four years
  complete(COVID, 
           DISTRICT.NAME = dist_cons$DISTRICT.NAME,
           fill = list(GRID.COV.T = 0)) %>% 
  dplyr::select(-NO.CELLS.TOT) %>% 
  left_join(dist_cons)

# for number of lists per district
temp3 <- temp01 %>% 
  # summarising metrics of interest (more districts for no.lists than for coverage)
  group_by(COVID, DISTRICT.NAME) %>% 
  summarise(NO.LISTS = n_distinct(GROUP.ID)) %>% 
  ungroup() %>% 
  # only considering districts covered at least once in the four years
  complete(COVID, 
           DISTRICT.NAME = dist_cons1$DISTRICT.NAME,
           fill = list(NO.LISTS = 0)) %>% 
  # since DUR is two years
  mutate(NO.LISTS = ifelse(COVID == "DUR", floor(NO.LISTS/2), NO.LISTS)) %>% 
  left_join(dist_cons1)

data_spread0 <- temp3 %>% 
  left_join(temp1) %>% 
  left_join(temp2) %>% 
  pivot_longer(cols = c("NO.LISTS", "GRID.COV", "GRID.COV.T"),
               names_to = "METRIC", values_to = "VALUE") %>% 
  # some NAs produced for grid coverage because those districts don't qualify for coverage
  # analysis but present in number of lists analysis, so need to remove them
  filter(!(is.na(VALUE))) %>% 
  pivot_wider(names_from = "COVID", values_from = "VALUE") %>% 
  # calculating change (produces NA for x == 0 & y == 0 which need to be removed)
  # number of lists proportional change also has threshold of 10 lists (in function)
  mutate(RAW.CHANGE1 = s_spread_change(BEF, DUR),
         RAW.CHANGE2 = s_spread_change(DUR, AFT),
         PROP.CHANGE1a = s_spread_propchange(METRIC, BEF, DUR),
         PROP.CHANGE1b = s_spread_propchange(METRIC, DUR, AFT),
         PROP.CHANGE2a = s_spread_propchange(METRIC, DUR, BEF),
         PROP.CHANGE2b = s_spread_propchange(METRIC, AFT, DUR)) %>% 
  # for district geometry
  left_join(grid_dist_base0)


transition_names <- data.frame(T.CODE = c("T1", "T2", "T3", "T4"),
                               T.LABEL = c("Before to During", "During to After",
                                           "During to Before", "After to During"))


##### Change in birding effort per district ####

# 1. map of raw change
# 2. with SEs of raw change
# 3. map of proportional change

# 1. map (to give an idea of overall clustering)

data_spread1 <- data_spread0 %>% 
  filter(METRIC == "NO.LISTS") %>% 
  distinct(DISTRICT.NAME, geometry, RAW.CHANGE1, RAW.CHANGE2) %>% 
  # pivoting longer for facetting
  pivot_longer(cols = c("RAW.CHANGE1", "RAW.CHANGE2"),
               names_to = "METRIC", values_to = "VALUE") %>% 
  mutate(T.CODE = case_when(str_detect(METRIC, "1") ~ "T1",
                            str_detect(METRIC, "2") ~ "T2")) %>% 
  left_join(transition_names)

s_spread_map <- ggplot(data_spread1) +
  geom_polygon(data = indiamap,
               aes(long, lat, group = group),
               fill = "#ACACAC", colour = "black", size = 0.4) +
  geom_sf(aes(fill = VALUE, geometry = geometry), col ="#ACACAC", size = 0.1) +
  facet_wrap(~ T.LABEL) +
  # scale_fill_continuous_divergingx(palette = "RdBu", mid = 0,
  #                                  n_interp = 7, na.value = "grey") +
  scale_fill_stepsn(colours = RColorBrewer::brewer.pal(n = 7, name = "RdBu"),
                    breaks = c(-1000, -500, -100, 0, 100, 500, 1000),
                    values = scales::rescale(c(-4134, -1000, -500, -100, 0, 
                                               100, 500, 1000, 7848)), 
                    limits = c(-4134, 7848),
                    na.value = "#ACACAC") +
  labs(x = "Longitude", y = "Latitude",
       fill = "Difference in\nno. of lists",
       title = "Change in no. of lists per district in transition periods",
       subtitle = "Grey: districts not considered in analysis")
# not considered can be either because both time periods are zero, or if generally no 
# district-grid cell link present

ggsave(filename = glue("03_wrap_figs/{anal_name}_1effort_a.png"), 
       plot = s_spread_map,
       dpi = 300, width = 14, height = 8, units = "in")



# 2. with SEs

data_spread2 <- data_spread1 %>% 
  # removing NA cells (when both periods of the transition are zero)
  filter(!is.na(VALUE)) %>% 
  group_by(T.CODE, T.LABEL) %>% 
  # this gives B number of means of bootstrapped samples
  dplyr::summarise(VALUE = boot_conf(x = VALUE)) %>% 
  group_by(T.CODE, T.LABEL) %>% 
  dplyr::summarise(CI.L = stats::quantile(VALUE, 0.025), # Obtain the CIs
                   CI.U = stats::quantile(VALUE, 0.975),
                   VALUE = median(VALUE)) 

s_spread_rawchange <- ggplot(data_spread2, aes(x = T.LABEL, y = VALUE)) + 
  geom_point(size = 4, position = position_dodge(0.5)) +
  geom_errorbar(aes(ymin = CI.L, ymax = CI.U), 
                size = 1.75, width = 0.08, position = position_dodge(0.5)) +
  # scale_y_continuous(limits = c(1.1, 2.3), breaks = seq(1, 3, 0.2)) +
  labs(title = "Net change in birding effort (no. of lists) across districts\nin transition periods",
       x = "Transition", y = "Difference in no. of lists") 

ggsave(filename = glue("03_wrap_figs/{anal_name}_1effort_b.png"), 
       plot = s_spread_rawchange,
       dpi = 300, width = 6, height = 9, units = "in")

# is DUR-AFT really lower than BEF-DUR?
ggplot(data_spread1) +
  geom_histogram(aes(VALUE)) +
  facet_wrap(~ T.LABEL)


# 3. map

# forward direction
data_spread3a <- data_spread0 %>% 
  filter(METRIC == "NO.LISTS") %>% 
  distinct(DISTRICT.NAME, geometry, PROP.CHANGE1a, PROP.CHANGE1b) %>% 
  # pivoting longer for facetting
  pivot_longer(cols = c("PROP.CHANGE1a", "PROP.CHANGE1b"),
               names_to = "METRIC", values_to = "VALUE") %>% 
  mutate(T.CODE = case_when(str_detect(METRIC, "a") ~ "T1",
                            str_detect(METRIC, "b") ~ "T2")) %>% 
  left_join(transition_names) %>% 
  # keeping only negative change
  mutate(VALUE = ifelse(VALUE < 0, VALUE, NA_real_))

# backward direction
data_spread3b <- data_spread0 %>% 
  filter(METRIC == "NO.LISTS") %>% 
  distinct(DISTRICT.NAME, geometry, PROP.CHANGE2a, PROP.CHANGE2b) %>% 
  # pivoting longer for facetting
  pivot_longer(cols = c("PROP.CHANGE2a", "PROP.CHANGE2b"),
               names_to = "METRIC", values_to = "VALUE") %>% 
  mutate(T.CODE = case_when(str_detect(METRIC, "a") ~ "T3",
                            str_detect(METRIC, "b") ~ "T4")) %>% 
  left_join(transition_names) %>% 
  # keeping only negative change
  mutate(VALUE = ifelse(VALUE < 0, VALUE, NA_real_)) %>% 
  # order
  mutate(T.LABEL = factor(T.LABEL, levels = c("After to During", "During to Before")))


s_spread_mapprop <- (ggplot(data_spread3a) +
  geom_polygon(data = indiamap,
               aes(long, lat, group = group),
               fill = "white", colour = "black", size = 0.4) +
  geom_sf(aes(fill = VALUE, geometry = geometry), col ="#ACACAC", size = 0.1) +
  facet_wrap(~ T.LABEL) +
  # scale_fill_continuous_divergingx(palette = "RdBu", mid = 0,
  #                                  n_interp = 7, na.value = "grey") +
  scale_fill_steps2(low = viridisLite::cividis(5, direction = -1)[1],
                    mid = viridisLite::cividis(5, direction = -1)[3],
                    high = viridisLite::cividis(5, direction = -1)[5],
                    midpoint = -0.45,
                    breaks = c(-1, -0.9, -0.65, -0.45, -0.25, -0.1, -0),
                    limits = c(-1, 0),
                    na.value = "#ACACAC") +
  labs(x = "Longitude", y = "Latitude",
       fill = "Proportional change")) /
  (ggplot(data_spread3b) +
  geom_polygon(data = indiamap,
               aes(long, lat, group = group),
               fill = "white", colour = "black", size = 0.4) +
  geom_sf(aes(fill = VALUE, geometry = geometry), col ="#ACACAC", size = 0.1) +
  facet_wrap(~ T.LABEL) +
  # scale_fill_viridis_b(option = "cividis", direction = -1, na.value = "grey",
  #                      values = c(0.1, 0.25, 0.45, 0.65, 0.9)) +
  scale_fill_steps2(low = viridisLite::cividis(5, direction = -1)[1],
                    mid = viridisLite::cividis(5, direction = -1)[3],
                    high = viridisLite::cividis(5, direction = -1)[5],
                    midpoint = -0.45,
                    breaks = c(-1, -0.9, -0.65, -0.45, -0.25, -0.1, -0),
                    limits = c(-1, 0),
                    na.value = "#ACACAC") +
  labs(x = "Longitude", y = "Latitude",
       fill = "Proportional change")) +
  plot_layout(guides = "collect") +
  plot_annotation(title = "Proportional declines in no. of lists per district in transition periods (only when N1 >= 10)",
                  subtitle = "Grey: districts with positive proportional change\nWhite: districts not considered in analysis")

ggsave(filename = glue("03_wrap_figs/{anal_name}_1effort_c.png"), 
       plot = s_spread_mapprop,
       dpi = 300, width = 14, height = 15, units = "in")


##### Change in grid coverage per district (without & with threshold) ####

# 1. map of raw change
# 2. with SEs of raw change
# 3. map of proportional change

coverage_types <- data.frame(METRIC = c("GRID.COV", "GRID.COV.T"),
                             METRIC.LABEL = c("Coverage (%)", "Coverage with threshold (%)"))

# 1. map (to give an idea of overall clustering)

data_spread4 <- data_spread0 %>% 
  filter(METRIC == "GRID.COV" | METRIC == "GRID.COV.T") %>% 
  distinct(METRIC, DISTRICT.NAME, geometry, RAW.CHANGE1, RAW.CHANGE2) %>% 
  # pivoting longer for facetting
  pivot_longer(cols = c("RAW.CHANGE1", "RAW.CHANGE2"),
               names_to = "CHANGE.TYPE", values_to = "VALUE") %>% 
  mutate(T.CODE = case_when(str_detect(CHANGE.TYPE, "1") ~ "T1",
                            str_detect(CHANGE.TYPE, "2") ~ "T2")) %>% 
  left_join(transition_names) %>% 
  left_join(coverage_types)

s_spread_gridcov_map <- ggplot(data_spread4) +
  geom_polygon(data = indiamap,
               aes(long, lat, group = group),
               fill = "#ACACAC", colour = "black", size = 0.4) +
  geom_sf(aes(fill = VALUE, geometry = geometry), col ="#ACACAC", size = 0.1) +
  facet_grid(METRIC.LABEL ~ T.LABEL, switch = "y") +
  scale_fill_stepsn(colours = RColorBrewer::brewer.pal(n = 9, name = "RdBu"),
                    breaks = c(-40, -25, -10, -1, 1, 10, 25, 40),
                    values = scales::rescale(c(-100, -40, -25, -10, -1, 1, 10, 25, 40, 100)), 
                    limits = c(-100, 100),
                    na.value = "#ACACAC") +
  labs(x = "Longitude", y = "Latitude",
       fill = "Difference in\ngrid coverage",
       title = "Change in grid coverage per district in transition periods",
       subtitle = "Grey: districts not considered in analysis")

ggsave(filename = glue("03_wrap_figs/{anal_name}_2gridcov_a.png"), 
       plot = s_spread_gridcov_map,
       dpi = 300, width = 14, height = 14, units = "in")


# 2. with SEs

data_spread5 <- data_spread4 %>% 
  # removing NA cells (when both periods of the transition are zero)
  filter(!is.na(VALUE)) %>% 
  group_by(METRIC, METRIC.LABEL, T.CODE, T.LABEL) %>% 
  # this gives B number of means of bootstrapped samples
  dplyr::summarise(VALUE = boot_conf(x = VALUE)) %>% 
  group_by(METRIC, METRIC.LABEL, T.CODE, T.LABEL) %>% 
  dplyr::summarise(CI.L = stats::quantile(VALUE, 0.025), # Obtain the CIs
                   CI.U = stats::quantile(VALUE, 0.975),
                   VALUE = median(VALUE)) 

s_spread_gridcov_rawchange <- ggplot(data_spread5, aes(x = T.LABEL, y = VALUE)) + 
  facet_wrap(~ METRIC.LABEL, nrow = 2) +
  geom_point(size = 4, position = position_dodge(0.5)) +
  geom_errorbar(aes(ymin = CI.L, ymax = CI.U), 
                size = 1.75, width = 0.08, position = position_dodge(0.5)) +
  # scale_y_continuous(limits = c(1.1, 2.3), breaks = seq(1, 3, 0.2)) +
  labs(title = "Net change in grid coverage across districts\nin transition periods",
       x = "Transition", y = "Difference in grid coverage") 

ggsave(filename = glue("03_wrap_figs/{anal_name}_2gridcov_b.png"), 
       plot = s_spread_gridcov_rawchange,
       dpi = 300, width = 6, height = 9, units = "in")


# 3. map

data_spread6 <- data_spread0 %>% 
  filter(METRIC == "GRID.COV" | METRIC == "GRID.COV.T") %>% 
  distinct(METRIC, DISTRICT.NAME, geometry, 
           PROP.CHANGE1a, PROP.CHANGE1b, PROP.CHANGE2a, PROP.CHANGE2b) %>% 
  # pivoting longer for facetting
  pivot_longer(cols = c("PROP.CHANGE1a", "PROP.CHANGE1b",
                        "PROP.CHANGE2a", "PROP.CHANGE2b"),
               names_to = "CHANGE.TYPE", values_to = "VALUE") %>% 
  mutate(T.CODE = case_when(str_detect(CHANGE.TYPE, "1a") ~ "T1",
                            str_detect(CHANGE.TYPE, "1b") ~ "T2",
                            str_detect(CHANGE.TYPE, "2a") ~ "T3",
                            str_detect(CHANGE.TYPE, "2b") ~ "T4")) %>% 
  left_join(transition_names) %>% 
  left_join(coverage_types) %>% 
  # keeping only negative change
  mutate(VALUE = ifelse(VALUE < 0, VALUE, NA_real_)) %>% 
  mutate(T.LABEL = factor(T.LABEL, levels = c("Before to During", "During to After",
                                              "After to During", "During to Before")))

# with the threshold, the IQR of proportional change has increased even though range is smaller
# i.e., the distribution is much more rounded
# this results in more districts with higher declines, but what's important here is to
# compare bef-dur with aft-dur and see which districts overlap---not many
# then compare these two with dur-aft and dur-bef respectively to check whether changes are 
# only in one direction---evidently not

s_spread_gridcov_mapprop_a <- ggplot(data_spread6 %>% 
                                       filter(METRIC == "GRID.COV")) +
  geom_polygon(data = indiamap,
               aes(long, lat, group = group),
               fill = "white", colour = "black", size = 0.4) +
  geom_sf(aes(fill = VALUE, geometry = geometry), col ="#ACACAC", size = 0.1) +
  facet_wrap(~ T.LABEL, ncol = 2) +
  scale_fill_steps2(low = viridisLite::cividis(5, direction = -1)[1],
                    mid = viridisLite::cividis(5, direction = -1)[3],
                    high = viridisLite::cividis(5, direction = -1)[5],
                    midpoint = -0.45,
                    breaks = c(-1, -0.9, -0.65, -0.45, -0.25, -0.1, -0),
                    limits = c(-1, 0),
                    na.value = "#ACACAC") +
  labs(x = "Longitude", y = "Latitude",
       fill = "Proportional change",
       title = "Proportional declines in grid coverage per district in transition periods",
       subtitle = "Grey: districts with positive proportional change\nWhite: districts not considered in analysis")

ggsave(filename = glue("03_wrap_figs/{anal_name}_2gridcov_c1.png"), 
       plot = s_spread_gridcov_mapprop_a,
       dpi = 300, width = 14, height = 14, units = "in")

s_spread_gridcov_mapprop_b <- ggplot(data_spread6 %>% 
                                       filter(METRIC == "GRID.COV.T")) +
  geom_polygon(data = indiamap,
               aes(long, lat, group = group),
               fill = "white", colour = "black", size = 0.4) +
  geom_sf(aes(fill = VALUE, geometry = geometry), col ="#ACACAC", size = 0.1) +
  facet_wrap(~ T.LABEL, ncol = 2) +
  scale_fill_steps2(low = viridisLite::cividis(5, direction = -1)[1],
                    mid = viridisLite::cividis(5, direction = -1)[3],
                    high = viridisLite::cividis(5, direction = -1)[5],
                    midpoint = -0.45,
                    breaks = c(-1, -0.9, -0.65, -0.45, -0.25, -0.1, -0),
                    limits = c(-1, 0),
                    na.value = "#ACACAC") +
  labs(x = "Longitude", y = "Latitude",
       fill = "Proportional change",
       title = "Proportional declines in grid coverage per district (with threshold) in transition periods",
       subtitle = "Grey: districts with positive proportional change\nWhite: districts not considered in analysis")

ggsave(filename = glue("03_wrap_figs/{anal_name}_2gridcov_c2.png"), 
       plot = s_spread_gridcov_mapprop_b,
       dpi = 300, width = 14, height = 14, units = "in")

# all these values are zero in one of the two transition periods.

```

-   In terms of pure no. of lists, overall birding effort was not notably affected by the pandemic. From the map of raw change, it is clear that more districts had negative change from DUR to AFT than from BEF to DUR. But it also seems that major and worrisome changes were in very few cases. Most importantly, there was no prominent clustering in these major worrisome changes.
-   Comparing proportional change in no. of lists in both directions, specifically BEF-DUR with AFT-DUR which tells us the effect of the pandemic, we see that most major changes (bright yellow) are in central and northern India and also that there is in general little overlap between the two transitions. What this means is that while there is obvious variability in birding effort between different years, the direct effect of the pandemic on this variability (inferred from overlapping areas of high proportional decline in BEF-DUR and AFT-DUR) is not great. In fact, in some cases, some major declines in BEF-DUR are not major in AFT-DUR and vice-versa, meaning that these instead may point to annual idiosyncrasies. This is solidified by the presence of a similar number of districts showing prominent negative change in the transitions DUR-BEF and DUR-AFT. The presence of many more yellow districts in the reverse direction than in the forward direction points to the general increase in birding efforts.
-   Overall grid coverage across all districts increased during the pandemic, while it either increased (without threshold) or stayed the same (with threshold) after. Looking into this deeper, it is clear that major worrisome changes are actually very few, and most importantly, there aren't major spatial clusters of these major changes.
-   Like with no. of lists, in some East-Central Indian districts grid coverage also showed major declines due to the pandemic (and bounced back after). Aside from these few districts, there is little overlap. Moreover, there are more districts with major declines in the other directions, i.e., DUR-BEF and DUR-AFT, which suggests that there is general growth.
-   With the threshold for coverage, the only declines that remain are the ones where one of the periods has zero coverage. Again, there is very little overlap of these districts, and there are no major spatial clusters. It also looks like several districts were covered during the pandemic that weren't covered before or after!

### Temporal spread

Not "per observer", as this metric from data POV.

Since month is not considered here (and instead data from multiple months are averaged), it doesn't make sense to keep two years for BEF and AFT---they should instead also be pooled into the averaging.

Here, running models is not necessary, as we just want to visualise the patterns. Robust results for this do not tell us much. Besides, the models that can be run for this metric would be very different from those for the other metrics (no CELL.ID or OBSERVER.ID random effect, and MONTH used as random effect; response has more than 2 values).

```{r d10a_t_dow, cache=TRUE, message=FALSE}

anal_name <- "d10a_t_dow"

##### Change in DoW spread ####

met_week <- function(dates) {
  require(lubridate)
  
  normalyear <- c((0:363 %/% 7 + 1), 52)
  leapyear   <- c(normalyear[1:59], 9, normalyear[60:365])
  yearday    <- yday(dates)
  
  return(ifelse(leap_year(dates), leapyear[yearday], normalyear[yearday])) 
}


data_a <- data0_MY_d_slice_G %>% 
  mutate(WEEK.Y = met_week(OBSERVATION.DATE)) %>% 
  mutate(DAY.W = wday(OBSERVATION.DATE, 
                      # start week from Monday
                      week_start = getOption("lubridate.week.start", 1)),
         DAY.W.LABEL = wday(OBSERVATION.DATE, 
                            week_start = getOption("lubridate.week.start", 1),
                            label = T)) %>% 
  group_by(M.YEAR, WEEK.Y) %>% 
  mutate(TOT.LISTS = n_distinct(SAMPLING.EVENT.IDENTIFIER)) %>%
  group_by(M.YEAR, WEEK.Y, DAY.W, DAY.W.LABEL) %>% 
  dplyr::summarise(TOT.LISTS = min(TOT.LISTS),
                   DAY.LISTS = replace_na(n_distinct(SAMPLING.EVENT.IDENTIFIER)),
                   PROP.LISTS = DAY.LISTS/TOT.LISTS) %>% 
  group_by(M.YEAR, DAY.W, DAY.W.LABEL) %>% 
  dplyr::summarise(PROP.LISTS = boot_conf(PROP.LISTS)) %>% 
  group_by(M.YEAR, DAY.W, DAY.W.LABEL) %>% 
  dplyr::summarise(CI.L = stats::quantile(PROP.LISTS, 0.025), # Obtain the CIs
                   CI.U = stats::quantile(PROP.LISTS, 0.975),
                   PROP.LISTS = median(PROP.LISTS)) 

data_b <- data0_MY_d_slice_G %>% 
  filter(STATE %in% anal_states[1,]) %>% 
  mutate(STATE = factor(STATE, levels = anal_states[1,]),
         WEEK.Y = met_week(OBSERVATION.DATE)) %>% 
  mutate(DAY.W = wday(OBSERVATION.DATE, 
                      # start week from Monday
                      week_start = getOption("lubridate.week.start", 1)),
         DAY.W.LABEL = wday(OBSERVATION.DATE, 
                            week_start = getOption("lubridate.week.start", 1),
                            label = T)) %>% 
  group_by(M.YEAR, STATE, WEEK.Y) %>% 
  mutate(TOT.LISTS = n_distinct(SAMPLING.EVENT.IDENTIFIER)) %>%
  group_by(M.YEAR, STATE, WEEK.Y, DAY.W, DAY.W.LABEL) %>% 
  dplyr::summarise(TOT.LISTS = min(TOT.LISTS),
                   DAY.LISTS = replace_na(n_distinct(SAMPLING.EVENT.IDENTIFIER)),
                   PROP.LISTS = DAY.LISTS/TOT.LISTS) %>% 
  group_by(M.YEAR, STATE, DAY.W, DAY.W.LABEL) %>% 
  dplyr::summarise(PROP.LISTS = boot_conf(PROP.LISTS)) %>% 
  group_by(M.YEAR, STATE, DAY.W, DAY.W.LABEL) %>% 
  dplyr::summarise(CI.L = stats::quantile(PROP.LISTS, 0.025), # Obtain the CIs
                   CI.U = stats::quantile(PROP.LISTS, 0.975),
                   PROP.LISTS = median(PROP.LISTS)) 


plot_a <- ggplot(data_a, aes(DAY.W.LABEL, PROP.LISTS, colour = M.YEAR)) + 
  geom_point(size = 3, position = position_dodge(0.5)) +
  geom_errorbar(aes(ymin = CI.L, ymax = CI.U), 
                size = 1.25, width = 0.4, position = position_dodge(0.5)) +
  scale_colour_manual(values = covid_palette, name = "Migratory\nyear") +
  labs(title = "National level",
       x = "Day of week", y = "Proportion of lists")

ggsave(filename = glue("03_wrap_figs/{anal_name}_a.png"), plot = plot_a,
       dpi = 300, width = 11, height = 6, units = "in")


plot_b <- ggplot(data_b, aes(DAY.W.LABEL, PROP.LISTS, colour = M.YEAR)) + 
  facet_wrap(~ STATE, ncol = 2, scales = "free_y") +
  geom_point(size = 3.5, position = position_dodge(0.5)) +
  geom_errorbar(aes(ymin = CI.L, ymax = CI.U), 
                size = 1.5, width = 0.5, position = position_dodge(0.5)) +
  scale_colour_manual(values = covid_palette, name = "Migratory\nyear") +
  labs(title = "State-level",
       x = "Day of week", y = "Proportion of lists")

ggsave(filename = glue("03_wrap_figs/{anal_name}_b.png"), plot = plot_b,
       dpi = 300, width = 22, height = 13, units = "in")

```

```{r d10b_t_tod, cache=TRUE, message=FALSE}

anal_name <- "d10b_t_tod"

##### Change in ToD spread ####

data_a <- data0_MY_d_slice_G %>% 
  mutate(DAY.Y = yday(OBSERVATION.DATE)) %>% 
  group_by(M.YEAR, DAY.Y) %>% 
  mutate(TOT.LISTS = replace_na(n_distinct(SAMPLING.EVENT.IDENTIFIER))) %>%
  group_by(M.YEAR, DAY.Y, HOUR) %>% 
  dplyr::summarise(TOT.LISTS = min(TOT.LISTS),
                   HOUR.LISTS = replace_na(n_distinct(SAMPLING.EVENT.IDENTIFIER)),
                   PROP.LISTS = HOUR.LISTS/TOT.LISTS) %>% 
  group_by(M.YEAR) %>% 
  complete(HOUR = 0:23, fill = list(PROP.LISTS = 0)) %>% 
  group_by(M.YEAR, HOUR) %>% 
  dplyr::summarise(PROP.LISTS = boot_conf(PROP.LISTS)) %>% 
  group_by(M.YEAR, HOUR) %>% 
  dplyr::summarise(CI.L = stats::quantile(PROP.LISTS, 0.025), # Obtain the CIs
                   CI.U = stats::quantile(PROP.LISTS, 0.975),
                   PROP.LISTS = median(PROP.LISTS)) 

data_b <- data0_MY_d_slice_G %>% 
  filter(STATE %in% anal_states[1,]) %>% 
  mutate(STATE = factor(STATE, levels = anal_states[1,]),
         DAY.Y = yday(OBSERVATION.DATE)) %>% 
  group_by(M.YEAR, STATE, DAY.Y) %>% 
  mutate(TOT.LISTS = replace_na(n_distinct(SAMPLING.EVENT.IDENTIFIER))) %>%
  group_by(M.YEAR, STATE, DAY.Y, HOUR) %>% 
  dplyr::summarise(TOT.LISTS = min(TOT.LISTS),
                   HOUR.LISTS = replace_na(n_distinct(SAMPLING.EVENT.IDENTIFIER)),
                   PROP.LISTS = HOUR.LISTS/TOT.LISTS) %>% 
  group_by(M.YEAR, STATE) %>% 
  complete(HOUR = 0:23, fill = list(PROP.LISTS = 0)) %>% 
  group_by(M.YEAR, STATE, HOUR) %>% 
  dplyr::summarise(PROP.LISTS = boot_conf(PROP.LISTS)) %>% 
  group_by(M.YEAR, STATE, HOUR) %>% 
  dplyr::summarise(CI.L = stats::quantile(PROP.LISTS, 0.025), # Obtain the CIs
                   CI.U = stats::quantile(PROP.LISTS, 0.975),
                   PROP.LISTS = median(PROP.LISTS)) 


plot_a <- ggplot(data_a, aes(HOUR, PROP.LISTS, colour = M.YEAR)) + 
  geom_point(size = 2, position = position_dodge(0.8)) +
  geom_errorbar(aes(ymin = CI.L, ymax = CI.U), 
                size = 1.2, width = 0.6, position = position_dodge(0.8)) +
  scale_colour_manual(values = covid_palette, name = "Migratory\nyear") +
  scale_x_continuous(limits = c(-1, 24), breaks = 0:23) +
  labs(title = "National level",
       x = "Time of day (hours)", y = "Proportion of lists")

ggsave(filename = glue("03_wrap_figs/{anal_name}_a.png"), plot = plot_a,
       dpi = 300, width = 16, height = 8, units = "in")


plot_b <- ggplot(data_b, aes(HOUR, PROP.LISTS, colour = M.YEAR)) + 
  facet_wrap(~ STATE, ncol = 2, scales = "free_y") +
  geom_point(size = 2.5, position = position_dodge(0.8)) +
  geom_errorbar(aes(ymin = CI.L, ymax = CI.U), 
                size = 1.4, width = 0.6, position = position_dodge(0.8)) +
  scale_colour_manual(values = covid_palette, name = "Migratory\nyear") +
  scale_x_continuous(limits = c(-1, 24), breaks = 0:23) +
  labs(title = "State-level",
       x = "Time of day (hours)", y = "Proportion of lists")

ggsave(filename = glue("03_wrap_figs/{anal_name}_b.png"), plot = plot_b,
       dpi = 300, width = 32, height = 17, units = "in")

```
